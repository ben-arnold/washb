<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>washb package vignette • washb</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="washb package vignette">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">washb</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.2.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/washb.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>washb package vignette</h1>
                        <h4 class="author">Andrew Mertens and Ben Arnold</h4>
            
            <h4 class="date">2018-09-27</h4>
      
      
      <div class="hidden name"><code>washb.Rmd</code></div>

    </div>

    
    
<div id="vignette-overview" class="section level1">
<h1 class="hasAnchor">
<a href="#vignette-overview" class="anchor"></a>Vignette overview</h1>
<p>The <code>washb</code> R package was developed to help standardize and facilitate intention-to-treat analyses in the WASH Benefits trial. This vignette provides an overview of the main functions included in package. As an illustrative example, the vignette uses the Bangladesh trial primary outcomes (diarrhea, length-for-age Z-scores) to calculate several unadjusted and adjusted estimates of intervention effects. It illustrates a range of different estimators from unadjusted approaches such as the paired t-test (see <code>washb_ttest</code>) to targeted maximum likelihood estimation with ensemble machine learning (see <code>washb_tmle</code>).</p>
<p>For unadjusted analyses in a paired design, the paired t-test (<code>washb_ttest</code>) for continuous outcomes and Mantel-Haenszel pooled risk difference or ratio (<code>washb_mh</code>) are “oldies but goodies” – they provide a simple and robust way to compare outcomes between arms. However, for unpaired analyses and/or any type of adjusted analyses, you should consider regression (<code>washb_glm</code>) or semi-parametric, double-robust (<code>washb_tmle</code>) estimators.</p>
<div id="brief-description-of-functions-documented-in-the-vignette" class="section level3">
<h3 class="hasAnchor">
<a href="#brief-description-of-functions-documented-in-the-vignette" class="anchor"></a>Brief description of functions documented in the vignette</h3>
<ul>
<li><p><code>washb_mean</code> Means estimated with robust standard errors for the WASH Benefits trials. Calculate means for a variable along with robust sandwich SEs and 95% confidence intervals that account for clustering within id.</p></li>
<li><p><code>washb_ttest</code> Implements a paired t-test to compare continuous outcomes between two arms of the study.</p></li>
<li><p><code>washb_mh</code> Implements the pooled Mantel-Haenszel estimator of the ITT prevalence ratio or difference between two arms of the study.</p></li>
<li><p><code>washb_glm</code> Estimates ITT effects using generalized linear models (GLM) with robust standard errors for unadjusted and adjusted estimates. Includes conversions of coefficients to relative risks (for binary outcomes), calculates confidence intervals, and prescreens possible adjustment covariates using the internal <code>washb_prescreen</code> function. Can be used for subgroup analyses (tests of effect modification).</p></li>
<li><p><code>washb_tmle</code> Estimates ITT effects using targeted maximum likelihood estimation, which is particularly useful for adjusted analyses. Like <code>washb_glm</code>, this function provides measures of effect on absolute and relative scales (for binary outcomes), and pre-screens possible adjustment covariates using the internal <code>washb_prescreen</code> function. Unlike other estimation approaches in the package, <code>washb_tmle</code> can account for missing outcomes that may be missing systematically by treatment arm or baseline covariates.</p></li>
<li><p><code>washb_permute</code> Conducts a permutation test of the independence of an outcome by treatment arm, conditional on randomization block using the Wilcoxon rank-sum test statistic.</p></li>
<li>Internal package functions (only used internally by the main package functions):</li>
<li>
<code>washb_prescreen</code> Pre-screens adjustment covariates – restrict to those with a LR test P&lt;0.2 (or user-set p-value). Called internally in the <code>washb_glm</code> and <code>washb_tmle</code> functions, or can be called on its own.</li>
<li>
<code>sandwichSE</code> Calculates the Huber Sandwich Estimator for robust standard errors (<a href="http://www.stat.berkeley.edu/~census/mlesan.pdf">Freedman 2006</a>).</li>
<li><p><code>washb_lincom</code> Estimates SEs, CIs, and P-values for Pr&gt;|Z| from a linear combination of GLM regression coefficients.</p></li>
</ul>
</div>
</div>
<div id="getting-started" class="section level1">
<h1 class="hasAnchor">
<a href="#getting-started" class="anchor"></a>Getting started</h1>
<div id="r-resources" class="section level3">
<h3 class="hasAnchor">
<a href="#r-resources" class="anchor"></a>R resources</h3>
<p>For new users of R, the following sources are helpful learning resources:<br>
1. <a href="http://dlab.berkeley.edu/event-host/d-lab">Calendar of UC Berkeley D-Lab workshops</a> (Look for R bootcamps)<br>
2. <a href="http://www.cookbook-r.com/">Cookbook for R</a><br>
3. <a href="https://www.datacamp.com/courses/r-for-sas-spss-and-stata-users-r-tutorial">Datacamp: R for SAS, SPSS, and Stata users</a> (This course is for those familiar with statistical programming who only need to learn R-specific syntax. Great GUI learning interface, and free for introductory course, and academic discount for paid courses.)<br>
4. <a href="http://tryr.codeschool.com/">Try R codeschool</a> (An interactive introductory course)<br>
5. <a href="http://statistics.ats.ucla.edu/stat/r/">UCLA Institute For Digital Research and Education: R resources</a> (Great source for topic-specific tutorials)<br>
6. <a href="http://www.r-tutor.com/r-introduction">R -tutor introduction</a><br>
7. <a href="https://www.coursera.org/learn/r-programming">Johns Hopkins Coursera course in R programming</a></p>
</div>
<div id="installation-from-github" class="section level3">
<h3 class="hasAnchor">
<a href="#installation-from-github" class="anchor"></a>Installation from GitHub</h3>
<p>The WASH Benefits R package is developed on GitHub: <a href="https://ben-arnold.github.io/washb" class="uri">https://ben-arnold.github.io/washb</a>. To install the R package from GitHub, you will need the <code>devtools</code> package. From within R, you can install <code>devtools</code> with the code: <code>install.packages("devtools")</code>. This only needs to occur once (per computer). After installation, load the <code>devtools</code> package (type <code>library(devtools)</code>), and then install the <code>washb</code> package by typing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"ben-arnold/washb"</span>)</code></pre></div>
<p>We will periodically update the <code>washb</code> package with improvements and bug fixes. When a new package version is available, the UCB team will send an email to notify the WASHB community of the update. You can always ensure you have the latest version by re-installing the package. If you encounter a bug, find something frustrating or confusing, or have suggestions for improvements email Andrew and Ben to let them know!</p>
</div>
<div id="installing-required-packages" class="section level3">
<h3 class="hasAnchor">
<a href="#installing-required-packages" class="anchor"></a>Installing required packages</h3>
<p>The <code>washb</code> package relies on several functions found in a few different packages that extend the basic R installation. These packages need to be installed onto each computer once, and loaded into the R workspace each time R is opened. If you are installing the packages for the first time, use the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">"sandwich"</span>)
<span class="kw">install.packages</span>(<span class="st">"lmtest"</span>)
<span class="kw">install.packages</span>(<span class="st">"coin"</span>)
<span class="kw">install.packages</span>(<span class="st">"plyr"</span>)
<span class="kw">install.packages</span>(<span class="st">"metafor"</span>)</code></pre></div>
<p>If you plan to use targeted maximum likelihood estimation and machine learning through the <code>washb_tmle</code> function you will additionally need to install:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">"tmle"</span>)
<span class="kw">install.packages</span>(<span class="st">"SuperLearner"</span>)</code></pre></div>
<p>Once packages are installed for the first time, they will be automatically loaded along with the <code>washb</code> package when you load the package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(washb)</code></pre></div>
<pre><code>## Welcome to the washb package</code></pre>
<pre><code>## Version: 0.2.1</code></pre>
<pre><code>## Created on 2017-02-02</code></pre>
<pre><code>## 
## This software was developed with funding from the
## Bill &amp; Melinda Gates Foundation (grant number OPPGD759).
## 
## The package's reference manual and vignette are also online:
## https://ben-arnold.github.io/washb</code></pre>
<p>The <code>library()</code> command can be used to load any installed package. It is not needed for any of the required packages listed above, but it is for suggested packages. For example, to fit a negative binomial GLM model, the  package is required, and can be installed once with <code>install.packages("MASS")</code> and loaded each time R is opened with <code>library("MASS")</code>.</p>
<p>Suggested packages include: nnlsm, zoo, arm, MASS, Matrix, lme4, gam, splines, foreach, and glmnet.</p>
</div>
<div id="package-documentation" class="section level3">
<h3 class="hasAnchor">
<a href="#package-documentation" class="anchor"></a>Package documentation</h3>
<p>Use <code>??washb</code> to see full list of package documentation, or use <code>?function_name</code> to see help documentation for any specific package. For example, <code><a href="../reference/washb_glm.html">?washb_glm</a></code> returns the help page for the <code>washb_glm</code> function.</p>
</div>
<div id="a-note-on-clustered-ses" class="section level3">
<h3 class="hasAnchor">
<a href="#a-note-on-clustered-ses" class="anchor"></a>A note on clustered SEs</h3>
<p><strong>IMPORTANT</strong> Read this at least once if you are a WASH B investigator.</p>
<p>The WASH Benefits trials were designed as pair-matched, cluster-randomized trials. The pair-matching is sometimes not immediately obvious because the trial has so many arms. But, we enrolled clusters in groups of 8 geographically contiguous clusters (9 in Kenya, due to the passive control arm) and then allocated the clusters to either one of six intervention arms or the double-sized control (<a href="http://bmjopen.bmj.com/content/3/8/e003476.short">Arnold et al. 2013</a>). It is a geographically pair-matched design, because any comparison between two arms is pair-matched within the randomization block. For example, within a randomization block there will be one cluster allocated to the Nutrition arm “matched” to 2 clusters allocated to the control arm.</p>
<p>Our inference assumes that clusters are independent units. That is important for estimating effects, because if clusters were not independent then we could have contamination (spillover) between arms and it would be impossible to use randomization alone to identify the intervention effects. (We formally tested this assumption in the Bangladesh trial and found no evidence for between-cluster spillover effects; tests for Kenya will be complete by late October.)</p>
<p>To correctly estimate the variance in the pair-matched design, we need to treat the independent unit as the pair (randomization block), because there is some dependence in the outcome induced by matching.</p>
<p>When is it reasonable to treat clusters as the independent unit? First, when estimating the marginal mean of a variable, perhaps by trial arm with <code>washb_means</code>, then there will be little/no difference between treating clusters versus pairs as the independent unit since with the exception of the control arm there are no replicated units within pair. In designs that are not pair-matched, such as the NIH R21 substudy (where sanitation and control clusters were not enrolled within matched pairs), then it is reasonable to treat the cluster as the independent unit. Treating the pairs/blocks as the independent unit is never wrong, it will just be slightly conservative in analyses that are not pair-matched.</p>
</div>
<div id="diarrhea-data-processing" class="section level3">
<h3 class="hasAnchor">
<a href="#diarrhea-data-processing" class="anchor"></a>Diarrhea data processing</h3>
<p>Below we will use some actual analyses from the Bangladesh trial to illustrate the different functions. To do that, we also need to read in final analysis datasets, merge them to baseline characteristics, and merge on the actual (unblinded) treatment assignments. We also do a little bit of minimal data processing to help facilitate the analyses.</p>
<p>This is an example of how to load and merge the enrollment and diarrhea data, with the actual treatment assignments. It creates a final analysis data frame called <code>dd</code> (for diarrhea data). At this time, these datasets are not included with the package – if you need access to them, please email the UCB team.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load and merge the final analysis files</span>
<span class="co"># treatment assignments, enrollment characteristics, and diarrhea measurements</span>
<span class="co"># note: these are unblinded treatment assignments in the encrypted volume 0-treatment-assignments</span>
<span class="co"># if you do not have access to these data through Dropbox, but need it, please contact UCB</span>
washb_bd_enrol &lt;-<span class="st"> </span>washb_bd_anthro &lt;-<span class="st"> </span><span class="ot">NULL</span>

washb_bd_tr    &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">"PrimaryOutcomeData/washb-bang-tr.csv"</span>)
washb_bd_enrol &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">"PrimaryOutcomeData/washb-bangladesh-enrol.csv"</span>)
washb_bd_diar  &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">"PrimaryOutcomeData/washb-bangladesh-diar.csv"</span>)

<span class="co"># drop svydate and month because they are superseded in the child level diarrhea data</span>
washb_bd_enrol<span class="op">$</span>svydate &lt;-<span class="st"> </span><span class="ot">NULL</span>
washb_bd_enrol<span class="op">$</span>month &lt;-<span class="st"> </span><span class="ot">NULL</span>

<span class="co"># merge the treatment assignments to the baseline dataset</span>
dd &lt;-<span class="st"> </span><span class="kw">merge</span>(washb_bd_enrol,washb_bd_tr,<span class="dt">by=</span><span class="kw">c</span>(<span class="st">"clusterid"</span>,<span class="st">"block"</span>),<span class="dt">all.x=</span>T,<span class="dt">all.y=</span>T)

<span class="co"># merge the baseline data with diarrhea measurements (keep only compounds with follow-up data)</span>
dd &lt;-<span class="st"> </span><span class="kw">merge</span>(dd,washb_bd_diar,<span class="dt">by=</span><span class="kw">c</span>(<span class="st">"dataid"</span>,<span class="st">"clusterid"</span>,<span class="st">"block"</span>),<span class="dt">all.x=</span>F,<span class="dt">all.y=</span>T)

<span class="co"># subset to post-intervention measurements: Year 1 or Year 2</span>
dd &lt;-<span class="st"> </span><span class="kw">subset</span>(dd,svy<span class="op">==</span><span class="dv">1</span><span class="op">|</span>svy<span class="op">==</span><span class="dv">2</span>)

<span class="co"># exclude new births that are not index children</span>
dd &lt;-<span class="st"> </span><span class="kw">subset</span>(dd,sibnewbirth<span class="op">==</span><span class="dv">0</span>)

<span class="co"># exclude children with missing data</span>
dd &lt;-<span class="st"> </span><span class="kw">subset</span>(dd,<span class="op">!</span><span class="kw">is.na</span>(dd<span class="op">$</span>diar7d))

<span class="co"># re-order the tr factor for convenience</span>
dd<span class="op">$</span>tr &lt;-<span class="st"> </span><span class="kw">factor</span>(dd<span class="op">$</span>tr,<span class="dt">levels=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Water"</span>,<span class="st">"Sanitation"</span>,<span class="st">"Handwashing"</span>,<span class="st">"WSH"</span>,<span class="st">"Nutrition"</span>,<span class="st">"Nutrition + WSH"</span>))

<span class="co"># ensure that month is coded as a factor</span>
dd<span class="op">$</span>month &lt;-<span class="st"> </span><span class="kw">factor</span>(dd<span class="op">$</span>month)

<span class="co"># sort the data for perfect replication when using random splits for V-fold cross-validation (washb_tmle and adj permutation tests)</span>
dd &lt;-<span class="st"> </span>dd[<span class="kw">order</span>(dd<span class="op">$</span>block,dd<span class="op">$</span>clusterid,dd<span class="op">$</span>dataid,dd<span class="op">$</span>childid),]</code></pre></div>
</div>
<div id="laz-data-processing" class="section level3">
<h3 class="hasAnchor">
<a href="#laz-data-processing" class="anchor"></a>LAZ data processing</h3>
<p>This is an example of how to load and merge the anthropometry and enrollment datasets. It pretty much parallels the processing steps of the diarrhea data (above). It creates a final analysis data frame called <code>lazd</code>. At this time, the anthropometry dataset is not included with the package – if you need access to it, please email the UCB team.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the anthropometry dataset</span>
washb_bd_anthro &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">"PrimaryOutcomeData/washb-bangladesh-anthro.csv"</span>)

<span class="co">#  merge to final analysis files, loaded above (keep only compounds with follow-up data)</span>
lazd &lt;-<span class="st"> </span><span class="kw">merge</span>(washb_bd_enrol,washb_bd_tr,<span class="dt">by=</span><span class="kw">c</span>(<span class="st">"clusterid"</span>,<span class="st">"block"</span>),<span class="dt">all.x=</span>T,<span class="dt">all.y=</span>T)
lazd &lt;-<span class="st"> </span><span class="kw">merge</span>(lazd,washb_bd_anthro,<span class="dt">by=</span><span class="kw">c</span>(<span class="st">"dataid"</span>,<span class="st">"clusterid"</span>,<span class="st">"block"</span>),<span class="dt">all.x=</span>F,<span class="dt">all.y=</span>T)

<span class="co"># subset to the index (target) children measured in Year 2 (primary outcome)</span>
lazd &lt;-<span class="st"> </span><span class="kw">subset</span>(lazd,svy<span class="op">==</span><span class="dv">2</span>)
lazd &lt;-<span class="st"> </span><span class="kw">subset</span>(lazd,tchild<span class="op">==</span><span class="st">"Target child"</span>)

<span class="co"># drop children with extreme LAZ values</span>
lazd &lt;-<span class="st"> </span><span class="kw">subset</span>(lazd,laz_x<span class="op">!=</span><span class="dv">1</span>)

<span class="co"># re-order the tr factor for convenience</span>
lazd<span class="op">$</span>tr &lt;-<span class="st"> </span><span class="kw">factor</span>(lazd<span class="op">$</span>tr,<span class="dt">levels=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Water"</span>,<span class="st">"Sanitation"</span>,<span class="st">"Handwashing"</span>,<span class="st">"WSH"</span>,<span class="st">"Nutrition"</span>,<span class="st">"Nutrition + WSH"</span>))

<span class="co"># ensure that month is coded as a factor</span>
lazd<span class="op">$</span>month &lt;-<span class="st"> </span><span class="kw">factor</span>(lazd<span class="op">$</span>month)

<span class="co"># rename aged to agedays (for consistency with the diarrhea file)</span>
lazd<span class="op">$</span>agedays &lt;-<span class="st"> </span>lazd<span class="op">$</span>aged

<span class="co"># sort the data for perfect replication when using random splits for V-fold cross-validation (washb_tmle and adj permutation tests)</span>
lazd &lt;-<span class="st"> </span>lazd[<span class="kw">order</span>(lazd<span class="op">$</span>block,lazd<span class="op">$</span>clusterid,lazd<span class="op">$</span>dataid,lazd<span class="op">$</span>childid),]</code></pre></div>
<p>Now that the dataset is cleaned and merged, the <code>washb</code> package functions can be applied and the results will match the WASH Benefits Bangladesh primary analysis.</p>
</div>
</div>
<div id="washb_mean" class="section level1">
<h1 class="hasAnchor">
<a href="#washb_mean" class="anchor"></a>washb_mean</h1>
<div id="function-overview" class="section level3">
<h3 class="hasAnchor">
<a href="#function-overview" class="anchor"></a>function overview</h3>
<p>The <code>washb_mean</code> function is most useful for calculating variable means and confidence intervals – for example, calculating average compliance (uptake) within a given intervention arm, or calculating the average LAZ by arm or measurement round. In the WASH Benefits trials, the independent unit is typically the cluster, so the <code>id</code> argument should identify the cluster ID.</p>
<p><strong>Arguments:</strong><br><code>Y</code>= Outcome variable.<br><code>id</code>= ID variable for independent units (e.g., cluster ID).<br><code>print</code>= Logical. If  (default) the function will print the results.</p>
<p><strong>Usage:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/washb_mean.html">washb_mean</a></span>(Y,id,<span class="dt">print=</span><span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="example" class="section level3">
<h3 class="hasAnchor">
<a href="#example" class="anchor"></a>example</h3>
<p>Using the WASH Benefits enrollment survey data and the <code>washb_mean</code> function, the means and 95% confidence intervals of several maternal characteristics are calculated below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MomAge&lt;-<span class="kw"><a href="../reference/washb_mean.html">washb_mean</a></span>(<span class="dt">Y=</span>washb_bd_enrol<span class="op">$</span>momage,<span class="dt">id=</span>washb_bd_enrol<span class="op">$</span>clusterid)
MomEduY&lt;-<span class="kw"><a href="../reference/washb_mean.html">washb_mean</a></span>(<span class="dt">Y=</span>washb_bd_enrol<span class="op">$</span>momeduy,<span class="dt">id=</span>washb_bd_enrol<span class="op">$</span>clusterid)</code></pre></div>
<p>The <code>&lt;-</code> command assigns the output of <code>washb_mean</code> to the new objects called <code>MomAge</code> and <code>MomEduY</code> Notice how there are 20 missing observations in the <code>momage</code>, but none in the <code>momeduy</code> variable.</p>
<p>If you want to compare means between groups using a difference, prevalence ratio, or incidence ratio (depending on the outcome), use <code>washb_ttest</code> (for t-test of unadjusted continuous outcomes), or <code>washb_mh</code> (for Mantel-Haenszel test on unadjusted binary outcomes), <code>washb_glm</code> for unadjusted or adjusted estimates using generalized linear models, or <code>washb_tmle</code> for unadjusted or adjusted estimates using targeted maximum likelihood estimation.</p>
</div>
</div>
<div id="washb_ttest" class="section level1">
<h1 class="hasAnchor">
<a href="#washb_ttest" class="anchor"></a>washb_ttest</h1>
<div id="function-overview-1" class="section level3">
<h3 class="hasAnchor">
<a href="#function-overview-1" class="anchor"></a>function overview</h3>
<p><code>washb_ttest</code> conducts a paired t-test for the difference in a continuous outcome between two treatment arms. It estimates the paired t-test for differences in means within matched pair (randomization block). This function can be used for unadjusted analyses of continuous outcomes, where the parameter of interest is the difference in means.</p>
<p><strong>Arguments:</strong></p>
<p><code>Y</code>=binary outcome (in this example, Y= child length for age z-score <code>lazd$laz</code>)</p>
<p><code>tr</code>=binary treatment group variable, comparison group first</p>
<p><code>strat</code>=stratification variable (In WASH Benefits: the pair-matched block variable)</p>
<p><code>contrast</code>= character vector of the format <code>c("contrast1", "contrast2")</code> of the two factor levels within the treatment variable (“tr”) to compare. <code>"contrast1"</code> is the reference group and <code>"contrast2"</code> is the active comparison.</p>
<p><strong>Usage:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/washb_ttest.html">washb_ttest</a></span>(Y,tr,strat,contrast)</code></pre></div>
</div>
<div id="paired-t-test-for-mean-differences" class="section level3">
<h3 class="hasAnchor">
<a href="#paired-t-test-for-mean-differences" class="anchor"></a>paired t-test for mean differences</h3>
<p>Below, <code>washb_ttest</code> is used to conduct a paired t-test of the difference in LAZ between the nutrition arm and the control arm in the Bangladesh trial. The code chunk provides an example of how to “vectorize” the call across arms, which works because the <code>washb_ttest</code> returns a simple vector of numbers (this type of efficient programming does not work well with functions that return more complex output, such as <code>washb_glm</code> or <code>washb_tmle</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Run washb_ttest on Nutrition vs. control arm comparison</span>
ttest.C.N &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_ttest.html">washb_ttest</a></span>(<span class="dt">Y=</span>lazd<span class="op">$</span>laz,<span class="dt">tr=</span>lazd<span class="op">$</span>tr,<span class="dt">strat=</span>lazd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>, <span class="st">"Nutrition"</span>))
<span class="kw">round</span>(ttest.C.N,<span class="dv">4</span>)</code></pre></div>
<pre><code>  diff  ci.lb  ci.ub t-stat      p 
0.2526 0.1470 0.3581 4.7545 0.0000 </code></pre>
<p>Advanced R tip: for a function like <code>washb_ttest</code> that returns a simple vector or list of single parameter estimates, you can use <code>sapply</code> command to efficiently apply the function to all the treatment arm contrasts</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create vector of contrasts for the pre-specified hypothesis 1</span>
<span class="co"># (each intervention vs. control) to use sapply</span>
h1.contrasts &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Water"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Handwashing"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"WSH"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition + WSH"</span>))

<span class="co"># Use sapply to apply washb_ttest() across all contrasts</span>
diff.h1LAZ &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(h1.contrasts,washb_ttest,<span class="dt">Y=</span>lazd<span class="op">$</span>laz,<span class="dt">tr=</span>lazd<span class="op">$</span>tr,<span class="dt">strat=</span>lazd<span class="op">$</span>block))
<span class="kw">rownames</span>(diff.h1LAZ) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"Water v C"</span>,<span class="st">"Sanitation v C"</span>,<span class="st">"Handwashing v C"</span>,<span class="st">"WSH v C"</span>,<span class="st">"Nutrition v C"</span>,<span class="st">"Nutrition + WSH v C"</span>)
<span class="kw">round</span>(diff.h1LAZ,<span class="dv">4</span>)</code></pre></div>
<pre><code>                       diff   ci.lb  ci.ub  t-stat      p
Water v C           -0.0646 -0.1812 0.0520 -1.1015 0.2737
Sanitation v C      -0.0227 -0.1383 0.0928 -0.3913 0.6965
Handwashing v C     -0.0679 -0.1763 0.0404 -1.2458 0.2161
WSH v C              0.0174 -0.0930 0.1278  0.3135 0.7546
Nutrition v C        0.2526  0.1470 0.3581  4.7545 0.0000
Nutrition + WSH v C  0.1292  0.0166 0.2418  2.2797 0.0250</code></pre>
</div>
</div>
<div id="washb_mh" class="section level1">
<h1 class="hasAnchor">
<a href="#washb_mh" class="anchor"></a>washb_mh</h1>
<div id="function-overview-2" class="section level3">
<h3 class="hasAnchor">
<a href="#function-overview-2" class="anchor"></a>function overview</h3>
<p><code>washb_mh</code> estimates a treatment effect (either difference or ratio) for a binary outcome pooled across strata. In the WASH Benefits trials, this function can estimate the unadjusted prevalence difference or ratio accounting for pair-matching in the design (where pair is the stratifying variable).</p>
<p><strong>Arguments:</strong></p>
<p><code>Y</code>=binary outcome (in this example, Y= 7-day diarrheal disease recall <code>dd$diar7d</code>)<br><code>tr</code>=binary treatment group variable, comparison group first<br><code>strat</code>=stratification variable (In WASH Benefits: the pair-matched block variable)<br><code>contrast</code>= character vector of the format <code>c("contrast1", "contrast2")</code> of the two factor levels within the treatment variable (“tr”) to compare. <code>"contrast1"</code> is the reference group and <code>"contrast2"</code> is the active comparison.</p>
<p><code>measure</code>=measure of effect. RR = prev ratio, RD = prev difference</p>
<p><strong>Usage:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/washb_mh.html">washb_mh</a></span>(Y,tr,strat,contrast,<span class="dt">measure=</span><span class="st">"RR"</span>)</code></pre></div>
</div>
<div id="estimate-a-pooled-prevalence-or-risk-ratio" class="section level3">
<h3 class="hasAnchor">
<a href="#estimate-a-pooled-prevalence-or-risk-ratio" class="anchor"></a>estimate a pooled prevalence (or risk) ratio</h3>
<p>Apply washb_mh to the sanitation vs. control arm contrast (With the <code>round()</code> function added to clean output and keep it from spilling across multiple lines).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mh.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_mh.html">washb_mh</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">strat=</span>dd<span class="op">$</span>block,<span class="dt">measure=</span><span class="st">"RR"</span>)
<span class="kw">round</span>(mh.C.S,<span class="dv">4</span>)</code></pre></div>
<pre><code>     PR,    ci.lb    ci.ub    logPR se.logPR        Z        p 
  0.6085   0.4569   0.8102  -0.4968   0.1461  -3.4001   0.0007 </code></pre>
</div>
<div id="estimate-a-pooled-prevalence-or-risk-difference" class="section level3">
<h3 class="hasAnchor">
<a href="#estimate-a-pooled-prevalence-or-risk-difference" class="anchor"></a>estimate a pooled prevalence (or risk) difference</h3>
<p>The function washb_mh can also be used to calculate an unadjusted risk difference:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw"><a href="../reference/washb_mh.html">washb_mh</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">strat=</span>dd<span class="op">$</span>block,<span class="dt">measure=</span><span class="st">"RD"</span>),<span class="dv">4</span>)</code></pre></div>
<pre><code>     RD   se.RD   ci.lb   ci.ub       Z       p 
-0.0220  0.0059 -0.0335 -0.0105 -3.7396  0.0002 </code></pre>
<p>Advanced R tip: for a function like <code>washb_mh</code> that returns a simple vector or list of single parameter estimates, you can use <code>sapply</code> command to efficiently apply the function to all the treatment arm contrasts</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create vector of contrasts for the pre-specified hypothesis 1</span>
<span class="co"># (each intervention vs. control) to use sapply</span>
h1.contrasts &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Water"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Handwashing"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"WSH"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>),
                     <span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition + WSH"</span>))

<span class="co"># Apply sapply to run the function on each comparison in the h1.contrasts list</span>
diff.h1 &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(h1.contrasts,washb_mh,<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">strat=</span>dd<span class="op">$</span>block,<span class="dt">measure=</span><span class="st">"RR"</span>))
<span class="kw">rownames</span>(diff.h1) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"Water v C"</span>,<span class="st">"Sanitation v C"</span>,<span class="st">"Handwashing v C"</span>,<span class="st">"WSH v C"</span>,<span class="st">"Nutrition v C"</span>,<span class="st">"Nutrition + WSH v C"</span>)
<span class="kw">print</span>(<span class="kw">round</span>(diff.h1,<span class="dv">4</span>))</code></pre></div>
<pre><code>                       PR,  ci.lb  ci.ub   logPR se.logPR       Z      p
Water v C           0.8883 0.6966 1.1326 -0.1185   0.1240 -0.9556 0.3393
Sanitation v C      0.6085 0.4569 0.8102 -0.4968   0.1461 -3.4001 0.0007
Handwashing v C     0.6002 0.4526 0.7958 -0.5105   0.1440 -3.5463 0.0004
WSH v C             0.6917 0.5310 0.9010 -0.3686   0.1349 -2.7324 0.0063
Nutrition v C       0.6438 0.4872 0.8505 -0.4404   0.1421 -3.0990 0.0019
Nutrition + WSH v C 0.6193 0.4709 0.8146 -0.4791   0.1399 -3.4258 0.0006</code></pre>
</div>
</div>
<div id="washb_glm" class="section level1">
<h1 class="hasAnchor">
<a href="#washb_glm" class="anchor"></a>washb_glm</h1>
<div id="function-overview-3" class="section level3">
<h3 class="hasAnchor">
<a href="#function-overview-3" class="anchor"></a>function overview</h3>
<p><code>washb_glm</code> fits a generalized linear model to estimate intention-to-treat (ITT) effects in a trial. The <code>contrast</code> argument enables you to specify the arms that you wish to compare (reference group in the first argument, comparison group in the second). To estimate adjusted effects, you can provide a data frame of adjustment covariates using the <code>W</code> argument – by default, covariates are pre-screened to only include those that are associated with the outcome based on a likelihood ratio test. To over-ride the pre-screening algorithm for some or all covariates, use the <code>forcedW</code> argument.</p>
<p>If the design is pair-matched (all primary outcome analyses in WASH B should be pair matched), use the <code>pair</code> argument to specify an id variable for pairs, and specify the same variable in the <code>id</code> argument to get correct SEs. If the design is not pair-matched, then the id argument should identify the smallest independent unit in the trial (e.g., cluster). The function computes robust standard errors.</p>
<p>Note that this function automatically drops observations from the analysis if they are from a pair with no treatment contrast – this can happen with incomplete randomization blocks in the Kenya trial.</p>
<p>Note that for binary outcomes such as diarrhea, you can estimate the prevalence ratio in a GLM model using a log link (<code>family=binomial(link='log')</code>) rather than the canonical logit link (<code>family='binomial'</code>) to estimate the odds ratio (not recommended because ORs are harder to interpret). Occasionally, a GLM model with a non-canonical link will fail to converge, particularly if the data are sparse. If this occurs for a binomial family with the log link, we recommend a modified poisson regression to estimate prevalence ratio using the argument <code>family=poisson(link='log')</code>. See <a href="https://www.ncbi.nlm.nih.gov/pubmed/15033648">Zou 2004</a> and <a href="https://www.ncbi.nlm.nih.gov/pubmed/21841157">Yelland et al. 2011</a> for details.</p>
<p>Finally, <code>washb_glm</code> also makes it straight forward to estimate conditional (i.e., subgroup) effects using the optional <code>V</code> argument (example below).</p>
<p><strong>Arguments:</strong><br><code>Y</code>= Binary, count, or continuous outcome<br><code>tr</code>= binary treatment group variable, comparison group first<br><code>pair</code>=stratification variable (In WASH Benefits: the pair-matched block variable)<br><code>W</code>= Optional data frame that includes adjustment covariates (for adjusted estimates). <code>W</code> will be prescreened and only those associated with the outcome will be adjusted for. See washb_prescreen for more details.<br><code>forcedW</code>= Optional vector of variable names to force as adjustment covariates (no screening)<br><code>V</code>= Optional variable name for subgroup analyses, which is interacted with <code>tr</code>. Continuous variables can be used and an interaction term will be fit, but the calculated point estimates and confidence intervals for the treatment effect between subgroups will only be returned if V is a factor.<br><code>id</code>= id of cluster used in calculating robust standard errors.<br><code>contrast</code>= character vector of the format <code>c("contrast1", "contrast2")</code> of the two factor levels within the treatment variable (“tr”) to compare. <code>"contrast1"</code> is the reference group and <code>"contrast2"</code> is the active comparison. <code>family</code>= GLM model family (gaussian, binomial, poisson, and negative binomial). Use “binomial(link=‘log’)” to return prevalence ratios instead of odds ratios when the outcome is binary. Use “neg.binom” for a Negative binomial model.<br><code>pval</code>= level of p=value to use in prescreening the set of potential adjustment variables W. Any variable in W with a likelihood ratio test p-value below this threshold will be included in the final adjustment set. Defaults to 0.2<br><code>print</code>= logical (TRUE or FALSE, defaults to TRUE) for whether to print output or just store it in the assigned object.<br><code>verbose</code>= logical (TRUE or FALSE, defaults to FALSE) for whether to print a description of objects to the output.</p>
<p><strong>Usage:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(Y, tr, pair, <span class="dt">W=</span><span class="ot">NULL</span>, <span class="dt">forcedW=</span><span class="ot">NULL</span>, <span class="dt">V=</span><span class="ot">NULL</span>, id, contrast, <span class="dt">family=</span><span class="st">'gaussian'</span>, <span class="dt">pval=</span><span class="fl">0.2</span>, <span class="dt">print=</span><span class="ot">TRUE</span>)</code></pre></div>
<p><strong>Returned objects:</strong> * <code>objectname$TR</code> to return the treatment effect and inference.<br>
* <code>objectname$fit</code> to return full glm model estimates.<br>
* <code>objectname$vcv</code> to return the variance-covariance matrix.<br>
* <code>objectname$rowdropped</code> to return the vector list of observations included in the model fit.<br>
* <code>objectname$lincom</code> to return subgroup-specific conditional relative risk estimates if a subgroup <code>V</code> is specified.<br>
* <code>objectname$glmModel</code> to return the glm model fit to be used with <code>predict()</code> to return model predictions of the outcome. Note that this is the glm model fit <strong>without adjusting the standard errors for repeated measures</strong> so you should not use it for inference if the data include repeated observations and/or if you have fit a modified Poisson model. It is safest to use the returned <code>$TR</code> and <code>$fit</code> objects for inference, which include robust SEs.</p>
</div>
<div id="unadjusted-analysis-binary-outcome-ratio" class="section level3">
<h3 class="hasAnchor">
<a href="#unadjusted-analysis-binary-outcome-ratio" class="anchor"></a>unadjusted analysis (binary outcome ratio)</h3>
<p>As an example, the following code applies the <code>washb_glm</code> function to compare diarrhea prevalence between the sanitation and control arms. To estimate the prevalence ratio (PR), we fit the GLM model with a log link, <code>family=binomial(link='log')</code>. Occasionally, a glm model with a non-canonical link function like <code>family=binomial(link='log')</code> will fail to converge. If this occurs, use a modified poisson regression to estimate prevalence ratio using the argument <code>family=poisson(link='log')</code> (see details above for references).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Diar.glm.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block, <span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'log'</span>))</code></pre></div>
<pre><code>

-----------------------------------------
 GLM Fit: Sanitation vs. Control 
-----------------------------------------
                    PR      2.5%     97.5%   Estimate Std. Error   z value    Pr(&gt;|z|)
trSanitation 0.6109162 0.4510202 0.8274985 -0.4927955  0.1548202 -3.183019 0.001457482</code></pre>
<p>On top of the function’s auto-printed output, the <code>washb_glm</code> function contains a number of objects. For example, <code>'objectname'$TR</code> returns just the treatment effect of the intervention arm, useful when saving to a row of an R object containing only the treatment effects across all the desired arm contrasts.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(Diar.glm.C.S<span class="op">$</span>TR,<span class="dv">4</span>)</code></pre></div>
<pre><code>                 PR  2.5%  97.5% Estimate Std. Error z value Pr(&gt;|z|)
trSanitation 0.6109 0.451 0.8275  -0.4928     0.1548  -3.183   0.0015</code></pre>
<p>This result shows that the sanitation intervention led to a (1-0.61) = 39 percent relative reduction in diarrhea compared with the control arm.</p>
</div>
<div id="unadjusted-analysis-binary-outcome-difference" class="section level3">
<h3 class="hasAnchor">
<a href="#unadjusted-analysis-binary-outcome-difference" class="anchor"></a>unadjusted analysis (binary outcome difference)</h3>
<p>To estimate a difference between arms for a binary outcome (the prevalence difference or risk difference, depending on the outcome definition), the syntax is the same as the previous example except you need to use a different link to specify a linear (rather than log-linear) model: <code>family='gaussian'</code>. This is sometimes called a linear probability model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">RD.Diar.glm.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block, <span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="st">'gaussian'</span>)</code></pre></div>
<pre><code>

-----------------------------------------
 GLM Fit: Sanitation vs. Control 
-----------------------------------------
                   Coef.        2.5%      97.5% Std. Error   z value     Pr(&gt;|z|)
trSanitation -0.02200495 -0.03458109 -0.0094288  0.0064164 -3.429485 0.0006047275</code></pre>
<p>This result shows that the sanitation intervention led to a -2.2 precentage point (absolute) reduction in diarrhea compared with the control arm.</p>
</div>
<div id="unadjusted-analysis-continuous-outcome" class="section level3">
<h3 class="hasAnchor">
<a href="#unadjusted-analysis-continuous-outcome" class="anchor"></a>unadjusted analysis (continuous outcome)</h3>
<p>As an example, the following code applies the <code>washb_glm</code> function to compare LAZ scores between the sanitation and control arms of the trial. Since it is a pair-matched design, we specify <code>pair=lazd$block</code> and <code>id=lazd$block</code>, where <code>block</code> is the randomization block (identified matched pairs). For a continuous outcome, the family should be <code>family='gaussian'</code>. Finally, the <code>contrast</code> argument needs to correspond to different levels in the <code>tr</code> variable. In this example, <code>tr</code> is a factor with many levels, but we want to compare sanitation to control – the reference group should be listed first: <code>contrast=c("Control","Sanitation")</code>. The full command and results are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LAZ.glm.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>lazd<span class="op">$</span>laz,<span class="dt">tr=</span>lazd<span class="op">$</span>tr,<span class="dt">pair=</span>lazd<span class="op">$</span>block, <span class="dt">id=</span>lazd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="st">"gaussian"</span>, <span class="dt">verbose=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>

-----------------------------------------
 GLM Fit: Sanitation vs. Control 
-----------------------------------------
                   Coef.       2.5%      97.5% Std. Error    z value  Pr(&gt;|z|)
trSanitation -0.01862361 -0.1356985 0.09845124 0.05973207 -0.3117859 0.7552033</code></pre>
<p>This result shows there was no evidence for a difference in LAZ between the sanitation and control arms.</p>
</div>
<div id="adjusted-analyses" class="section level3">
<h3 class="hasAnchor">
<a href="#adjusted-analyses" class="anchor"></a>adjusted analyses</h3>
<p>The <code>W=</code> argument in <code>washb_glm</code> enables you to adjust for covariates in the GLM - <code>W</code> simply requires a data frame of potential adjustment covariates.</p>
<p>If you embark on adjusted analyses it can be convenient to make a vector that includes the adjustment variable names to screen for inclusion in adjusted GLM models. The convenience of this approach will be apparent in the examples below, where we repeatedly refer to this list of variables when subsetting the data to specify adjustment covariates.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># list of potential adjustment covariates</span>
Wadj &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"month"</span>,<span class="st">"agedays"</span>,<span class="st">"sex"</span>,<span class="st">"momage"</span>,<span class="st">"momedu"</span>,<span class="st">"momheight"</span>,<span class="st">"hfiacat"</span>,<span class="st">"Nlt18"</span>,<span class="st">"Ncomp"</span>,<span class="st">"watmin"</span>,<span class="st">"elec"</span>,<span class="st">"floor"</span>,<span class="st">"walls"</span>,<span class="st">"roof"</span>,<span class="st">"asset_wardrobe"</span>,<span class="st">"asset_table"</span>,<span class="st">"asset_chair"</span>,<span class="st">"asset_khat"</span>,<span class="st">"asset_chouki"</span>,<span class="st">"asset_tv"</span>,<span class="st">"asset_refrig"</span>,<span class="st">"asset_bike"</span>,<span class="st">"asset_moto"</span>,<span class="st">"asset_sewmach"</span>,<span class="st">"asset_mobile"</span>)</code></pre></div>
<p>For the diarrhea analysis data frame created above named <code>dd</code>, you can now subset it to the adjustment covariates above using the syntax: <code>dd[Wadj]</code>. Similarly, for the LAZ analysis data frame named <code>lazd</code>, you can subset it to adjustment covariates: <code>lazd[Wadj]</code>.</p>
<p>If <code>W</code> is specified, the <code>washb_glm</code> will pre-screen the covariates in the data frame provided in the <code>W=</code> argument. Variables with a p-value&lt;0.2 from a likelihood-ratio test are included as adjustment covariates in the final model. The <code>pval=</code> argument can be used to change the p-value threshold used to screen the covariates.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">adj.Diar.glm.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block, <span class="dt">W=</span>dd[Wadj], <span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'log'</span>))</code></pre></div>
<pre><code>
-----------------------------------------
Dropping 67 observations due to missing values in 1 or more variables
 Final sample size: 5210 
-----------------------------------------

-----------------------------------------
Pre-screening the adjustment covariates:
-----------------------------------------

Likelihood Ratio Test P-values:
               P-value
month          0.00000
agedays        0.00139
sex            0.69302
momage         0.95834
momedu         0.00023
momheight      0.47061
hfiacat        0.02598
Nlt18          0.41379
Ncomp          0.72487
watmin         0.07485
elec           0.00614
floor          0.05576
walls          0.63743
roof           0.94900
asset_wardrobe 0.10699
asset_table    0.07399
asset_chair    0.43212
asset_khat     0.00174
asset_chouki   0.60563
asset_tv       0.42975
asset_refrig   0.02540
asset_bike     0.48036
asset_moto     0.28840
asset_sewmach  0.13751
asset_mobile   0.59945


Covariates selected (P&lt;0.2):
                       P-value
month          0.0000000664917
agedays        0.0013854051931
momedu         0.0002294082996
hfiacat        0.0259780896649
watmin         0.0748457908310
elec           0.0061424259087
floor          0.0557563342543
asset_wardrobe 0.1069918101893
asset_table    0.0739884683794
asset_khat     0.0017386974934
asset_refrig   0.0254037503987
asset_sewmach  0.1375079553959


-----------------------------------------
 GLM Fit: Sanitation vs. Control 
-----------------------------------------
                    PR      2.5%     97.5%   Estimate Std. Error   z value    Pr(&gt;|z|)
trSanitation 0.5847469 0.4317727 0.7919187 -0.5365762  0.1547345 -3.467721 0.000524891

 RR of covariates
                                       PR      2.5%     97.5%
trSanitation                    0.5847469 0.4317727 0.7919187
month2                          0.4849529 0.1581594 1.4869765
month3                          0.4044081 0.1471559 1.1113787
month4                          1.1956219 0.6122722 2.3347652
month5                          1.0343119 0.4435036 2.4121587
month6                          2.0379062 0.8100683 5.1268043
month7                          1.1737215 0.4495119 3.0647067
month8                          1.6673212 0.6254334 4.4448537
month9                          0.3258038 0.1182398 0.8977361
month10                         0.2834488 0.1395233 0.5758405
month11                         0.5983482 0.1371178 2.6110440
month12                         0.6922535 0.1773029 2.7028034
agedays                         0.9993945 0.9990421 0.9997470
momeduPrimary (1-5y)            1.2507804 0.8158203 1.9176423
momeduSecondary (&gt;5y)           0.9339511 0.5751086 1.5166957
hfiacatMildly Food Insecure     1.1719294 0.6807637 2.0174674
hfiacatModerately Food Insecure 1.1108363 0.7919408 1.5581435
hfiacatSeverely Food Insecure   1.3250600 0.6893238 2.5471107
watmin                          0.9383602 0.8299307 1.0609560
elec                            0.8751570 0.6510430 1.1764198
floor                           1.2400760 0.6799353 2.2616689
asset_wardrobe                  1.0590677 0.6619020 1.6945475
asset_table                     0.9294539 0.7099895 1.2167569
asset_khat                      0.8254681 0.6264260 1.0877544
asset_refrig                    0.8144093 0.4206895 1.5766080
asset_sewmach                   0.8804924 0.4872256 1.5911867</code></pre>
<p><strong>Forced adjustment covariates</strong></p>
<p>If there are specific adjustment covariates you want to include in the GLM model, regardless of prescreening results, you can use the <code>forcedW</code> option. This argument takes a variable name or a vector of variable names. These variables must already be in the <code>W</code> dataframe of potential adjustment covariates. For example, if adjustment by age and sex is standard, force them into the GLM model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block, <span class="dt">W=</span>dd[Wadj], <span class="dt">forcedW=</span><span class="kw">c</span>(<span class="st">"agedays"</span>,<span class="st">"sex"</span>), <span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'log'</span>))</code></pre></div>
<pre><code>
-----------------------------------------
Dropping 67 observations due to missing values in 1 or more variables
 Final sample size: 5210 
-----------------------------------------

-----------------------------------------
Include the following adjustment covariates without screening:
-----------------------------------------
[1] "agedays" "sex"    

-----------------------------------------
Pre-screening the adjustment covariates:
-----------------------------------------

Likelihood Ratio Test P-values:
               P-value
month          0.00000
momage         0.95834
momedu         0.00023
momheight      0.47061
hfiacat        0.02598
Nlt18          0.41379
Ncomp          0.72487
watmin         0.07485
elec           0.00614
floor          0.05576
walls          0.63743
roof           0.94900
asset_wardrobe 0.10699
asset_table    0.07399
asset_chair    0.43212
asset_khat     0.00174
asset_chouki   0.60563
asset_tv       0.42975
asset_refrig   0.02540
asset_bike     0.48036
asset_moto     0.28840
asset_sewmach  0.13751
asset_mobile   0.59945


Covariates selected (P&lt;0.2):
                       P-value
month          0.0000000664917
momedu         0.0002294082996
hfiacat        0.0259780896649
watmin         0.0748457908310
elec           0.0061424259087
floor          0.0557563342543
asset_wardrobe 0.1069918101893
asset_table    0.0739884683794
asset_khat     0.0017386974934
asset_refrig   0.0254037503987
asset_sewmach  0.1375079553959


-----------------------------------------
 GLM Fit: Sanitation vs. Control 
-----------------------------------------
                    PR      2.5%     97.5%   Estimate Std. Error   z value     Pr(&gt;|z|)
trSanitation 0.5847484 0.4317425 0.7919783 -0.5365736  0.1547716 -3.466874 0.0005265495

 RR of covariates
                                       PR      2.5%     97.5%
trSanitation                    0.5847484 0.4317425 0.7919783
agedays                         0.9993945 0.9990414 0.9997478
sexmale                         0.9991030 0.7684642 1.2989634
month2                          0.4849484 0.1580972 1.4875339
month3                          0.4043968 0.1471298 1.1115136
month4                          1.1955974 0.6122445 2.3347747
month5                          1.0342857 0.4441253 2.4086600
month6                          2.0377791 0.8108934 5.1209488
month7                          1.1736033 0.4500471 3.0604461
month8                          1.6672885 0.6255902 4.4435652
month9                          0.3258044 0.1182710 0.8975029
month10                         0.2834577 0.1395702 0.5756837
month11                         0.5983104 0.1370407 2.6121825
month12                         0.6922687 0.1772347 2.7039619
momeduPrimary (1-5y)            1.2508399 0.8150730 1.9195833
momeduSecondary (&gt;5y)           0.9340191 0.5760518 1.5144325
hfiacatMildly Food Insecure     1.1718797 0.6794290 2.0212589
hfiacatModerately Food Insecure 1.1108493 0.7923887 1.5572990
hfiacatSeverely Food Insecure   1.3249358 0.6838226 2.5671203
watmin                          0.9383588 0.8301018 1.0607340
elec                            0.8751449 0.6511680 1.1761613
floor                           1.2401087 0.6798679 2.2620125
asset_wardrobe                  1.0590718 0.6618194 1.6947722
asset_table                     0.9294398 0.7093481 1.2178200
asset_khat                      0.8254342 0.6261901 1.0880746
asset_refrig                    0.8143569 0.4216935 1.5726522
asset_sewmach                   0.8805112 0.4874324 1.5905795</code></pre>
</div>
<div id="subgroup-analyses" class="section level3">
<h3 class="hasAnchor">
<a href="#subgroup-analyses" class="anchor"></a>subgroup analyses</h3>
<p>The <code>V</code> argument can be used to create an interaction term with <code>tr</code>, the treatment variable. You do not pass an actual vector to <code>V</code> – instead, you specify the string name of a variable that is included in the <code>W</code> matrix. Below is an example for a subgroup analysis of the effect of the nutrition intervention on diarrheal disease, stratified by index child (vs. non-index) – note how we include <code>"tchild"</code> in both the <code>forcedW</code> and <code>V</code> arguments – this ensures that the stratification variable isn’t dropped if it is not marginally significantly associated with the outcome.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimate subgroup analysis glm with washb_glm</span>
<span class="co"># stratified by index child status "tchild"</span>
glm.C.N.byChildType &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block, <span class="dt">W=</span>dd[<span class="st">"tchild"</span>], <span class="dt">V=</span><span class="st">"tchild"</span>, <span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>), <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'log'</span>), <span class="dt">verbose=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>
-----------------------------------------
Include the following adjustment covariates without screening:
-----------------------------------------
[1] "tchild"


-----------------------------------------
 GLM Fit: Nutrition vs. Control  by Subgroup: ' tchild '
-----------------------------------------
  Tr vs. C by Subgroup    est se.est est.lb est.ub       Z      P
1              Sibling 0.6255 0.3300 0.3276 1.1945 -1.4215 0.1552
2         Target child 0.6421 0.1742 0.4563 0.9035 -2.5425 0.0110


-----------------------------------------
 Significance of effect modification variables 
-----------------------------------------
                                PR  Pr(&gt;|z|)
trNutrition:VTarget child 1.026499 0.9360759</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Examine the treatment effect across subgroups with `objectname'$lincom</span>
glm.C.N.byChildType<span class="op">$</span>lincom</code></pre></div>
<pre><code>  Tr vs. C by Subgroup    est se.est est.lb est.ub       Z      P
1              Sibling 0.6255 0.3300 0.3276 1.1945 -1.4215 0.1552
2         Target child 0.6421 0.1742 0.4563 0.9035 -2.5425 0.0110</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimate subgroup analysis glm with washb_glm</span>
glm.C.N.byChildType &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block, <span class="dt">W=</span>dd[<span class="st">"tchild"</span>], <span class="dt">V=</span><span class="st">"tchild"</span>, <span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>), <span class="dt">family=</span><span class="st">"gaussian"</span>, <span class="dt">verbose=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>
-----------------------------------------
Include the following adjustment covariates without screening:
-----------------------------------------
[1] "tchild"


-----------------------------------------
 GLM Fit: Nutrition vs. Control  by Subgroup: ' tchild '
-----------------------------------------
  Tr vs. C by Subgroup     est se.est  est.lb  est.ub       Z      P
1              Sibling -0.0144 0.0103 -0.0346  0.0058 -1.3978 0.1622
2         Target child -0.0226 0.0080 -0.0383 -0.0068 -2.8116 0.0049


-----------------------------------------
 Significance of effect modification variables 
-----------------------------------------
                                Coef.  Pr(&gt;|z|)
trNutrition:VTarget child -0.00816172 0.4778686</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Examine the treatment effect across subgroups with `objectname'$lincom</span>
glm.C.N.byChildType<span class="op">$</span>lincom</code></pre></div>
<pre><code>  Tr vs. C by Subgroup     est se.est  est.lb  est.ub       Z      P
1              Sibling -0.0144 0.0103 -0.0346  0.0058 -1.3978 0.1622
2         Target child -0.0226 0.0080 -0.0383 -0.0068 -2.8116 0.0049</code></pre>
</div>
</div>
<div id="washb_tmle" class="section level1">
<h1 class="hasAnchor">
<a href="#washb_tmle" class="anchor"></a>washb_tmle</h1>
<p>Estimate intention-to-treat parameters using targeted maximum likelihood estimation (TMLE), potentially adjusted for covariates and missing outcomes</p>
<div id="function-overview-4" class="section level3">
<h3 class="hasAnchor">
<a href="#function-overview-4" class="anchor"></a>function overview</h3>
<p>The <code>washb_tmle</code> function is mainly a convenience wrapper for the <code>tmle</code> package. It estimates ITT effects in a trial using targeted maximum likelihood estimation (TMLE). In brief, the function does the following: it restricts the data to complete observations in the two arms listed in the <code>contrast</code> argument, it pre-screens covariates (<code>W</code>), if specified, to select those that have a univariate association with the outcome, and then it estimates the intention-to-treat effect using TMLE. If <code>family='binomial'</code>, then the function returns effects on the absolute, relative, and odds ratio scale. If <code>Delta</code> is specified (i.e., observations with missing outcomes are included), then the function will adjust the effects for missing values using inverse probability of censoring weights, with the weights estimated using data-adaptive super learning for <code>Pr(Delta|A,W)</code>.</p>
</div>
<div id="some-technical-details" class="section level3">
<h3 class="hasAnchor">
<a href="#some-technical-details" class="anchor"></a>some technical details</h3>
<p>If the analysis is pair-matched (as for primary outcomes), be sure to specify the pair ID in the <code>id</code> argument. Do not include pair IDs in the adjustment covariate set.</p>
<p>If you specify adjustment covariates (<code>W</code>), then by default <code>washb_tmle</code> pre-screens them and the subset that is associated with the outcome based on a likelihood ratio test are used in the estimation. There are some other important defaults to be aware of. First, <code>washb_tmle</code> estimates the treatment mechanism even though it is a randomized trial. There are two reasons for this – one theoretical and one practical. The theoretical reason is that estimating the treatment mechanism gains efficiency (see <a href="http://onlinelibrary.wiley.com/doi/10.1002/sim.7023/abstract">Balzer et al. 2016</a>); the practical reason is that unless the analysis is conducted at the cluster level (i.e., providing cluster means to the <code>washb_tmle</code> function), then the empirical treatment probabilities differ slightly due to varying cluster sizes. Estimating the treatment mechanism ensures that the variance calculation correctly accounts for the empirical treatment probabilities in the data.</p>
<p>Another default is that <code>washb_tmle</code> uses the <code>SuperLearner</code> algorithm to adjust for covariates and to predict the treatment mechanism and censoring mechanism (if adjusting for missing outcomes). The default algorithm library includes the simple mean, main terms GLM, main terms Bayes GLM with non-informative priors, generalized additive models (degree 2), and lasso (glmnet). These are the pre-specified algorithms from the original trial statistical analysis plan. You can type <code>listWrappers()</code> to see the full set of algorithms implemented in the super learner package. If you just want to use a main effects GLM model to adjust for the covariates with TMLE, then you can specify <code>Q.SL.library="SL.glm"</code>. If you are dealing with very small sample sizes (e.g., in a substudy), then you may wish to use even simpler libraries, such as a set of univariate regressions (as in <a href="http://onlinelibrary.wiley.com/doi/10.1002/sim.7023/abstract">Balzer et al. 2016</a>, but probably best to check with the UCB team before making big changes to the recommended algorithm library).</p>
<p>Finally, by default the function uses the same algorithm library to predict the outcome (<code>Q.SL.library</code>) and the treatment and censoring mechanisms. You can specify a different library for the treatment and censoring mechanisms using the <code>g.SL.library</code> argument.</p>
<p>If you want to adjust for missing outcomes in the analysis, then you need to include observations that have a missing outcome (<code>Y</code>) with <code>Delta=0</code> for those observations. Observations with missing outcomes should have treatment (<code>tr</code>) and covariate (<code>W</code>) information, which are used to create weights for <code>Pr(Delta|A,W)</code>.</p>
<p><strong>Arguments:</strong><br><code>Y</code>= Outcome variable (continuous, such as LAZ, or binary, such as diarrhea)<br><code>tr</code>= Treatment group variable (binary or factor)<br><code>W</code>= Data frame that includes adjustment covariates<br><code>id</code>= ID variable for independent units. For pair-matched designs, this is the matched pair and should be the same as the <code>pair</code> argument. For analyses that are not pair-matched, then it should typically be the cluster.<br><code>pair</code>= An optional ID variable to identify the matched pair unit (In WASH Benefits, blocks) if conducting a matched-pair analysis. This argument is used to drop pairs that are missing one or more treatment groups. Incomplete pairs is not an issue in the overall Bangladesh trial (there were no incomplete blocks), but is an issue in the Kenya trial where there were some incomplete blocks. <code>Delta</code>= indicator of missing outcome. 1 - observed, 0 - missing.<br><code>family</code>= Outcome family: <code>gaussian</code> (continuous outcomes, like LAZ) or <code>binomial</code> (binary outcomes like diarrhea or stunting)</p>
<p><code>contrast</code>= Vector of length 2 that includes the treatment groups to contrast (e.g., <code>contrast=c('Control','Nutrition')</code>)</p>
<p><code>Q.SL.Library</code>= Library of algorithms to include in the SuperLearner for the outcome model</p>
<p><code>g.SL.library</code>= Library of algorithms to include in the SuperLearner for the treatment model <span class="math inline">\(Pr(A|W)\)</span>, and for the missingness model <span class="math inline">\(Pr(\Delta|A,W)\)</span> (if <code>Delta</code> is specified)</p>
<p><code>pval</code>= The p-value threshold used to pre-screen covariates (<code>W</code>) based on a likelihood ratio test in a univariate regression with the outcome (<code>Y</code>). Variables with a univariate association p-value below this threshold will be used in the final model. Defaults to 0.2.</p>
<p><code>seed</code>= A seed for the pseudo-random cross-validation split used in model selection (use for perfectly reproducible results).</p>
<p><code>print</code>= Logical for printed output, defaults to true. If false, no output will be printed to the console if the returned object is saved to an R object.</p>
<p><strong>Usage:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/washb_tmle.html">washb_tmle</a></span>(Y,tr,<span class="dt">W=</span><span class="ot">NULL</span>,id,<span class="dt">pair=</span><span class="ot">NULL</span>, <span class="dt">Delta =</span> <span class="kw">rep</span>(<span class="dv">1</span>,<span class="kw">length</span>(Y)), <span class="dt">family=</span><span class="st">"gaussian"</span>, contrast, <span class="dt">Q.SL.library=</span><span class="kw">c</span>(<span class="st">"SL.mean"</span>,<span class="st">"SL.glm"</span>,<span class="st">"SL.bayesglm"</span>,<span class="st">"SL.gam"</span>,<span class="st">"SL.glmnet"</span>) ,<span class="dt">g.SL.library=</span>Q.SL.library, <span class="dt">pval=</span><span class="fl">0.2</span>, <span class="dt">seed=</span><span class="ot">NULL</span>, <span class="dt">print=</span><span class="ot">TRUE</span>)</code></pre></div>
<p><strong>References:</strong><br>
1. van der Laan MJ, Rose S. Targeted Learning: Causal Inference for Observational and Experimental Data. Springer Series in Statistics; 2011.<a href="http://www.springer.com/us/book/9781441997814">Link</a></p>
<ol start="2" style="list-style-type: decimal">
<li><p>Gruber S, van der Laan M. tmle: An R Package for Targeted Maximum Likelihood Estimation. J Stat Softw. 2012;51: 1–35.<a href="https://www.jstatsoft.org/article/view/v051i13">Link</a></p></li>
<li><p>Balzer LB, van der Laan MJ, Petersen ML, SEARCH Collaboration. Adaptive pre-specification in randomized trials with and without pair-matching. Stat Med. 2016; <a href="doi:10.1002/sim.7023" class="uri">doi:10.1002/sim.7023</a> <a href="http://onlinelibrary.wiley.com/doi/10.1002/sim.7023/abstract;jsessionid=F5CD1290B8DFF44C20FF303FBB08390F.f03t03">Link</a></p></li>
<li><p>Schuler MS, Rose S. Targeted Maximum Likelihood Estimation for Causal Inference in Observational Studies. Am J Epidemiol. 2017;185: 65–73. <a href="https://www.ncbi.nlm.nih.gov/pubmed/27941068">Link</a></p></li>
</ol>
</div>
<div id="tmle-for-a-continuous-outcome" class="section level3">
<h3 class="hasAnchor">
<a href="#tmle-for-a-continuous-outcome" class="anchor"></a>TMLE for a continuous outcome</h3>
<p>The <code>washb_tmle</code> has similar arguments as <code>washb_glm</code> (by design), with the addition of the super learner libraries. The default library (<code>c("SL.mean","SL.glm","SL.bayesglm","SL.gam","SL.glmnet")</code>) is pretty good in this context, so we don’t actually specify it below (instead relying on the default value).</p>
<p>Below, here is an example of estimating an adjusted difference in LAZ between the nutrition and control arms in the trial:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">adj.LAZ.tmle.C.N &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_tmle.html">washb_tmle</a></span>(<span class="dt">Y=</span>lazd<span class="op">$</span>laz,<span class="dt">tr=</span>lazd<span class="op">$</span>tr,<span class="dt">pair=</span>lazd<span class="op">$</span>block,<span class="dt">id=</span>lazd<span class="op">$</span>block, <span class="dt">W=</span>lazd[Wadj], <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>), <span class="dt">family=</span><span class="st">"gaussian"</span>)</code></pre></div>
<pre><code>
----------------------------------------- 
By specifying the pair argument,
you have indicated that this is a matched pair analysis.

Note: the analysis will only include pairs
that have a contrast in the treatment variable. 
-----------------------------------------
-----------------------------------------
Total of 10 observations dropped due to missing
values in one or more variables
  Final sample size: 1660 
-----------------------------------------

-----------------------------------------
Pre-screening the adjustment covariates
using a univariate liklihood ratio test:
-----------------------------------------

Likelihood Ratio Test P-values:
               P-value
month          0.00000
agedays        0.96208
sex            0.86270
momage         0.20990
momedu         0.00000
momheight      0.00000
hfiacat        0.00000
Nlt18          0.00055
Ncomp          0.07214
watmin         0.86821
elec           0.00000
floor          0.00000
walls          0.16072
roof           0.09029
asset_wardrobe 0.00000
asset_table    0.00027
asset_chair    0.00000
asset_khat     0.00000
asset_chouki   0.00111
asset_tv       0.00000
asset_refrig   0.00000
asset_bike     0.00904
asset_moto     0.00000
asset_sewmach  0.00006
asset_mobile   0.00000


Covariates selected (P&lt;0.2):
                    P-value
month          4.846005e-06
momedu         3.261193e-15
momheight      4.845440e-54
hfiacat        5.621381e-07
Nlt18          5.455514e-04
Ncomp          7.213989e-02
elec           1.398539e-10
floor          9.067623e-10
walls          1.607179e-01
roof           9.028871e-02
asset_wardrobe 8.376452e-14
asset_table    2.660365e-04
asset_chair    1.059169e-08
asset_khat     1.259119e-13
asset_chouki   1.109571e-03
asset_tv       4.039419e-16
asset_refrig   3.848861e-15
asset_bike     9.038690e-03
asset_moto     6.298749e-07
asset_sewmach  5.775318e-05
asset_mobile   3.976215e-06

-----------------------------------------

-----------------------------------------
Estimation Results:
-----------------------------------------
 Initial estimation of Q
     Procedure: SuperLearner
     Model:
         Y ~  SL.mean_All + SL.glm_All + SL.bayesglm_All + SL.gam_All + SL.glmnet_All

     Coefficients: 
         SL.mean_All    0 
          SL.glm_All    0 
     SL.bayesglm_All    0 
          SL.gam_All    0.0362053 
       SL.glmnet_All    0.9637947 

 Estimation of g (treatment mechanism)
     Procedure: SuperLearner 
     Model:
         A ~  SL.mean_All + SL.glm_All + SL.bayesglm_All + SL.gam_All + SL.glmnet_All 

     Coefficients: 
         SL.mean_All    1 
          SL.glm_All    0 
     SL.bayesglm_All    0 
          SL.gam_All    0 
       SL.glmnet_All    0 

 Estimation of g.Z (intermediate variable assignment mechanism)
     Procedure: No intermediate variable 

 Estimation of g.Delta (missingness mechanism)
     Procedure: No missingness 

 Bounds on g: ( 0.025 0.975 )

 Additive Effect
   Parameter Estimate:  0.27427
   Estimated Variance:  0.002319
              p-value:  0.000000012299
    95% Conf Interval: (0.17989, 0.36866) 

 Additive Effect among the Treated
   Parameter Estimate:  0.27427
   Estimated Variance:  0.0023185
              p-value:  0.000000012255
    95% Conf Interval: (0.1799, 0.36865) 

 Additive Effect among the Controls
   Parameter Estimate:  0.27427
   Estimated Variance:  0.0023193
              p-value:  0.000000012322
    95% Conf Interval: (0.17988, 0.36867) 

-----------------------------------------</code></pre>
<p>The default output notifies you if any observations were dropped due to missing values. It also summarizes the weighting of the models or algorithms used to estimate the outcome model (<code>estimation of Q</code>), the treatment mechanism (<code>estimation of g</code>), and the missingness mechanism (<code>estimation of g.Delta</code>).</p>
<p>The function returns an object of class <code>tmle</code> (you can see the  package for details). The effect estimate results are stored in the list <code>$estimates$ATE</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">unlist</span>(adj.LAZ.tmle.C.N<span class="op">$</span>estimates<span class="op">$</span>ATE)</code></pre></div>
<pre><code>             psi          var.psi              CI1              CI2           pvalue 
0.27427406478895 0.00231900076986 0.17988829595975 0.36865983361816 0.00000001229878 </code></pre>
</div>
<div id="tmle-for-a-binary-outcome" class="section level3">
<h3 class="hasAnchor">
<a href="#tmle-for-a-binary-outcome" class="anchor"></a>TMLE for a binary outcome</h3>
<p>For binary outcomes such as diarrhea, the <code>washb_tmle</code> syntax is almost unchanged but the family should be specified as <code>family="binomial"</code>. Unlike GLM, you don’t (and shouldn’t) specify the link function – TMLE is a non-parametric estimation approach, so it by default can estimate any function of the means in the treatment groups. The software currently estimates the difference, ratio, and odds ratio. You can access the different parameter estimates using the <code>estimates$</code> lists:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">adj.Diar.tmle.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_tmle.html">washb_tmle</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block,<span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">W=</span>dd[Wadj], <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="st">"binomial"</span>,<span class="dt">Q.SL.library=</span><span class="kw">c</span>(<span class="st">"SL.mean"</span>,<span class="st">"SL.glm"</span>,<span class="st">"SL.bayesglm"</span>,<span class="st">"SL.gam"</span>,<span class="st">"SL.glmnet"</span>))</code></pre></div>
<pre><code>
----------------------------------------- 
By specifying the pair argument,
you have indicated that this is a matched pair analysis.

Note: the analysis will only include pairs
that have a contrast in the treatment variable. 
-----------------------------------------
-----------------------------------------
Total of 67 observations dropped due to missing
values in one or more variables
  Final sample size: 5210 
-----------------------------------------

-----------------------------------------
Pre-screening the adjustment covariates
using a univariate liklihood ratio test:
-----------------------------------------

Likelihood Ratio Test P-values:
               P-value
month          0.00000
agedays        0.00138
sex            0.69302
momage         0.95823
momedu         0.00023
momheight      0.47178
hfiacat        0.02598
Nlt18          0.41119
Ncomp          0.72382
watmin         0.07505
elec           0.00614
floor          0.05576
walls          0.63743
roof           0.94900
asset_wardrobe 0.10699
asset_table    0.07399
asset_chair    0.43212
asset_khat     0.00174
asset_chouki   0.60563
asset_tv       0.42975
asset_refrig   0.02540
asset_bike     0.48036
asset_moto     0.28840
asset_sewmach  0.13751
asset_mobile   0.59945


Covariates selected (P&lt;0.2):
                       P-value
month          0.0000000664917
agedays        0.0013774954196
momedu         0.0002294082996
hfiacat        0.0259780896649
watmin         0.0750477584382
elec           0.0061424259087
floor          0.0557563342543
asset_wardrobe 0.1069918101894
asset_table    0.0739884683794
asset_khat     0.0017386974934
asset_refrig   0.0254037503987
asset_sewmach  0.1375079553959

-----------------------------------------

-----------------------------------------
Estimation Results:
-----------------------------------------
 Initial estimation of Q
     Procedure: SuperLearner
     Model:
         Y ~  SL.mean_All + SL.glm_All + SL.bayesglm_All + SL.gam_All + SL.glmnet_All

     Coefficients: 
         SL.mean_All    0.2859223 
          SL.glm_All    0 
     SL.bayesglm_All    0.7140777 
          SL.gam_All    0 
       SL.glmnet_All    0 

 Estimation of g (treatment mechanism)
     Procedure: SuperLearner 
     Model:
         A ~  SL.mean_All + SL.glm_All + SL.bayesglm_All + SL.gam_All + SL.glmnet_All 

     Coefficients: 
         SL.mean_All    0.7541792 
          SL.glm_All    0 
     SL.bayesglm_All    0 
          SL.gam_All    0 
       SL.glmnet_All    0.2458208 

 Estimation of g.Z (intermediate variable assignment mechanism)
     Procedure: No intermediate variable 

 Estimation of g.Delta (missingness mechanism)
     Procedure: No missingness 

 Bounds on g: ( 0.025 0.975 )

 Additive Effect
   Parameter Estimate:  -0.02283
   Estimated Variance:  0.000038619
              p-value:  0.00023902
    95% Conf Interval: (-0.035011, -0.01065) 

 Additive Effect among the Treated
   Parameter Estimate:  -0.022766
   Estimated Variance:  0.000038966
              p-value:  0.00026528
    95% Conf Interval: (-0.035001, -0.010531) 

 Additive Effect among the Controls
   Parameter Estimate:  -0.022832
   Estimated Variance:  0.000038507
              p-value:  0.00023375
    95% Conf Interval: (-0.034995, -0.01067) 

 Relative Risk
   Parameter Estimate:  0.60219
              p-value:  0.0007636
    95% Conf Interval: (0.44818, 0.80911) 

              log(RR):  -0.50719
    variance(log(RR)):  0.022709 

 Odds Ratio
   Parameter Estimate:  0.58795
              p-value:  0.00071402
    95% Conf Interval: (0.43226, 0.79971) 

              log(OR):  -0.53112
    variance(log(OR)):  0.024631 

-----------------------------------------</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># difference</span>
<span class="kw">round</span>(<span class="kw">unlist</span>(adj.Diar.tmle.C.S<span class="op">$</span>estimates<span class="op">$</span>ATE),<span class="dv">4</span>)</code></pre></div>
<pre><code>    psi var.psi     CI1     CI2  pvalue 
-0.0228  0.0000 -0.0350 -0.0107  0.0002 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># prevalence ratio</span>
<span class="kw">round</span>(<span class="kw">unlist</span>(adj.Diar.tmle.C.S<span class="op">$</span>estimates<span class="op">$</span>RR),<span class="dv">4</span>)</code></pre></div>
<pre><code>        psi         CI1         CI2      pvalue     log.psi var.log.psi 
     0.6022      0.4482      0.8091      0.0008     -0.5072      0.0227 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># odds ratio</span>
<span class="kw">round</span>(<span class="kw">unlist</span>(adj.Diar.tmle.C.S<span class="op">$</span>estimates<span class="op">$</span>OR),<span class="dv">4</span>)</code></pre></div>
<pre><code>        psi         CI1         CI2      pvalue     log.psi var.log.psi 
     0.5879      0.4323      0.7997      0.0007     -0.5311      0.0246 </code></pre>
</div>
<div id="tmle-with-inverse-probability-of-censoring-weights-ipcw" class="section level3">
<h3 class="hasAnchor">
<a href="#tmle-with-inverse-probability-of-censoring-weights-ipcw" class="anchor"></a>TMLE with inverse probability of censoring weights (IPCW)</h3>
<p>The <code>washb_tmle</code> function enables you to account for missing data in the outcome using inverse probability of censoring weights (IPCW) to the estimator. You can do this using the <code>Delta=</code> argument to specify an indicator of whether the outcome. A key step for conducting an IPCW analysis that differs from other analyses in this vignette is that you need to create the “full” data, where there is an observation for every potential measurement (i.e., including those that were missing in the trial). To do this, you need to use the enrolled study population, limited to live births (since the trial’s inference is limited to live births). Below, we provide an example using the control and nutrition arms in the Bangladesh trial.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#---------------------------------------</span>
<span class="co"># create a shell of the full data (dfull)</span>
<span class="co"># as if every index child with a live birth</span>
<span class="co"># were measured at year 1 and year 2</span>
<span class="co">#---------------------------------------</span>

washb_bd_track&lt;-<span class="ot">NULL</span>

washb_bd_track &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">"PrimaryOutcomeData/washb-bangladesh-track-compound.csv"</span>)

<span class="kw">table</span>(washb_bd_track<span class="op">$</span>miss1reason<span class="op">==</span><span class="st">"No live birth"</span>) <span class="co"># total number of unique compounds w/ live birth = 5190</span></code></pre></div>
<pre><code>
FALSE  TRUE 
 5190   361 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create the full data (i.e., a dataset with rows for every potential measurement)</span>
dfull &lt;-<span class="st"> </span><span class="kw">subset</span>(washb_bd_track,miss1reason<span class="op">!=</span><span class="st">"No live birth"</span>)
dfull<span class="op">$</span>svy &lt;-<span class="st"> </span><span class="dv">1</span>
dfull2 &lt;-<span class="st"> </span>dfull
dfull2<span class="op">$</span>svy &lt;-<span class="st"> </span><span class="dv">2</span>
dfull &lt;-<span class="st"> </span><span class="kw">rbind</span>(dfull,dfull2)

<span class="co"># merge treatment and enrollment data onto this shell of the full data</span>
dfull &lt;-<span class="st"> </span><span class="kw">merge</span>(dfull,washb_bd_tr,<span class="dt">by=</span><span class="kw">c</span>(<span class="st">"clusterid"</span>,<span class="st">"block"</span>, <span class="st">"tr"</span>),<span class="dt">all.x=</span>T,<span class="dt">all.y=</span>F)
dfull &lt;-<span class="st"> </span><span class="kw">merge</span>(dfull,washb_bd_enrol,<span class="dt">by=</span><span class="kw">c</span>(<span class="st">"dataid"</span>,<span class="st">"clusterid"</span>,<span class="st">"block"</span>),<span class="dt">all.x=</span>T,<span class="dt">all.y=</span>F)

<span class="co"># Since we are only analyzing the primary outcome at year 2 in this example</span>
<span class="co"># we need to re-subset the full data to year 2,</span>
<span class="co"># just before merging to the LAZ data (lazd, created above)</span>
dfull &lt;-<span class="st"> </span><span class="kw">subset</span>(dfull,svy<span class="op">==</span><span class="dv">2</span>)

<span class="co"># now merge the observed anthropometry outcomes (lazd) onto this full dataset</span>
lazdfull &lt;-<span class="st"> </span><span class="kw">merge</span>(dfull,washb_bd_anthro,<span class="dt">by=</span><span class="kw">c</span>(<span class="st">"dataid"</span>,<span class="st">"clusterid"</span>,<span class="st">"block"</span>,<span class="st">"svy"</span>),<span class="dt">all.x=</span>T,<span class="dt">all.y=</span>T)
lazdfull<span class="op">$</span>agedays &lt;-<span class="st"> </span>lazdfull<span class="op">$</span>aged <span class="co"># naming consisetncy across files</span>

<span class="co"># create an indicator equal to 1 if the outcome is observed, 0 otherwise</span>
lazdfull<span class="op">$</span>Delta &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">is.na</span>(lazdfull<span class="op">$</span>laz),<span class="dv">0</span>,<span class="dv">1</span>)
<span class="kw">table</span>(lazdfull<span class="op">$</span>Delta[lazdfull<span class="op">$</span>tr<span class="op">==</span><span class="st">"Control"</span><span class="op">|</span>lazdfull<span class="op">$</span>tr<span class="op">==</span><span class="st">"Nutrition"</span>])</code></pre></div>
<pre><code>
   0    1 
  34 3372 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set missing outcomes to an arbitrary, non-missing value. In this case use 9</span>
lazdfull<span class="op">$</span>Ydelta &lt;-<span class="st"> </span>lazdfull<span class="op">$</span>laz
lazdfull<span class="op">$</span>Ydelta[lazdfull<span class="op">$</span>Delta<span class="op">==</span><span class="dv">0</span>] &lt;-<span class="st"> </span><span class="dv">9</span>

<span class="co"># estimate an IPCW-TMLE parameter</span>
psi_ipcw &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_tmle.html">washb_tmle</a></span>(<span class="dt">Delta=</span>lazdfull<span class="op">$</span>Delta,<span class="dt">tr=</span>lazdfull<span class="op">$</span>tr, <span class="dt">id=</span>lazdfull<span class="op">$</span>block, <span class="dt">pair=</span>lazdfull<span class="op">$</span>block,<span class="dt">Y=</span>lazdfull<span class="op">$</span>Ydelta, <span class="dt">family=</span><span class="st">"gaussian"</span>, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>), <span class="dt">W=</span>lazdfull[Wadj], <span class="dt">seed=</span><span class="dv">12345</span>)</code></pre></div>
<pre><code>
----------------------------------------- 
By specifying the pair argument,
you have indicated that this is a matched pair analysis.

Note: the analysis will only include pairs
that have a contrast in the treatment variable. 
-----------------------------------------
-----------------------------------------
Total of 1724 observations dropped due to missing
values in one or more variables
  Final sample size: 1682 
-----------------------------------------

-----------------------------------------
Pre-screening the adjustment covariates
using a univariate liklihood ratio test:
-----------------------------------------

Likelihood Ratio Test P-values:
               P-value
month          0.06760
agedays        0.96208
sex            0.86270
momage         0.20990
momedu         0.00000
momheight      0.00000
hfiacat        0.00000
Nlt18          0.00055
Ncomp          0.07214
watmin         0.86821
elec           0.00000
floor          0.00000
walls          0.16072
roof           0.09029
asset_wardrobe 0.00000
asset_table    0.00027
asset_chair    0.00000
asset_khat     0.00000
asset_chouki   0.00111
asset_tv       0.00000
asset_refrig   0.00000
asset_bike     0.00904
asset_moto     0.00000
asset_sewmach  0.00006
asset_mobile   0.00000


Covariates selected (P&lt;0.2):
                    P-value
month          6.759682e-02
momedu         3.261193e-15
momheight      4.845440e-54
hfiacat        5.621381e-07
Nlt18          5.455514e-04
Ncomp          7.213989e-02
elec           1.398539e-10
floor          9.067623e-10
walls          1.607179e-01
roof           9.028871e-02
asset_wardrobe 8.376452e-14
asset_table    2.660365e-04
asset_chair    1.059169e-08
asset_khat     1.259119e-13
asset_chouki   1.109571e-03
asset_tv       4.039419e-16
asset_refrig   3.848861e-15
asset_bike     9.038690e-03
asset_moto     6.298749e-07
asset_sewmach  5.775318e-05
asset_mobile   3.976215e-06

-----------------------------------------

-----------------------------------------
Estimation Results:
-----------------------------------------
 Initial estimation of Q
     Procedure: SuperLearner
     Model:
         Y ~  SL.mean_All + SL.glm_All + SL.bayesglm_All + SL.gam_All + SL.glmnet_All

     Coefficients: 
         SL.mean_All    0 
          SL.glm_All    0 
     SL.bayesglm_All    0 
          SL.gam_All    0 
       SL.glmnet_All    1 

 Estimation of g (treatment mechanism)
     Procedure: SuperLearner 
     Model:
         A ~  SL.mean_All + SL.glm_All + SL.bayesglm_All + SL.gam_All + SL.glmnet_All 

     Coefficients: 
         SL.mean_All    0.5907074 
          SL.glm_All    0 
     SL.bayesglm_All    0.03792591 
          SL.gam_All    0 
       SL.glmnet_All    0.3713667 

 Estimation of g.Z (intermediate variable assignment mechanism)
     Procedure: No intermediate variable 

 Estimation of g.Delta (missingness mechanism)
     Procedure: SuperLearner 
     Model:
         Delta ~ SL.mean_All + SL.glm_All + SL.bayesglm_All + SL.gam_All + SL.glmnet_All 

     Coefficients: 
         SL.mean_All    1 
          SL.glm_All    0 
     SL.bayesglm_All    0 
          SL.gam_All    0 
       SL.glmnet_All    0 

 Bounds on g: ( 0.025 0.975 )

 Additive Effect
   Parameter Estimate:  0.2768
   Estimated Variance:  0.0023262
              p-value:  0.0000000095249
    95% Conf Interval: (0.18226, 0.37133) 

 Additive Effect among the Treated
   Parameter Estimate:  0.2768
   Estimated Variance:  0.0025443
              p-value:  0.000000040753
    95% Conf Interval: (0.17793, 0.37566) 

 Additive Effect among the Controls
   Parameter Estimate:  0.2768
   Estimated Variance:  0.0026254
              p-value:  0.000000065866
    95% Conf Interval: (0.17637, 0.37722) 

-----------------------------------------</code></pre>
<p>In this particular example, accounting for missing outcomes makes very little difference after adjusting for covariates – adjusted, and adjusted+IPCW estimates are nearly identical.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#---------------------------------------</span>
<span class="co"># compare the estimates</span>
<span class="co">#---------------------------------------</span>
<span class="kw">round</span>(<span class="kw">unlist</span>(adj.LAZ.tmle.C.N<span class="op">$</span>estimates<span class="op">$</span>ATE),<span class="dv">4</span>)</code></pre></div>
<pre><code>    psi var.psi     CI1     CI2  pvalue 
 0.2743  0.0023  0.1799  0.3687  0.0000 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">unlist</span>(psi_ipcw<span class="op">$</span>estimates<span class="op">$</span>ATE),<span class="dv">4</span>)</code></pre></div>
<pre><code>    psi var.psi     CI1     CI2  pvalue 
 0.2768  0.0023  0.1823  0.3713  0.0000 </code></pre>
</div>
</div>
<div id="comparison-of-itt-estimators" class="section level1">
<h1 class="hasAnchor">
<a href="#comparison-of-itt-estimators" class="anchor"></a>Comparison of ITT estimators</h1>
<p>In unadjusted ITT analyses, all the estimators we have discussed above are asymptotically equivalent. What this means is that as sample size increases to infinity, the estimates will converge to the same number. So, for unadjusted analyses, the choice of estimator is not very consequential. The primary analyses in Kenya and Bangladesh used paired t-tests (continuous) and stratified Mantel-Haenszel (binary) estimators for unadjusted analyses, and TMLE for adjusted analyses. GLM is a perfectly sensible approach as well, and one advantage of using GLM is that you can use the same estimator through all analyses (unadjusted, adjusted).</p>
<p>TMLE with super learning has some advantages in the adjusted analysis in that it will likely be more powerful than GLM because of the data-adaptive estimation in predicting the outcome. Note that a main effects GLM with covariates <em>is</em> a TMLE estimator as long as there are no interactions between covariates and the treatment arm, just assuming a parametric submodel (confused yet? See <a href="http://onlinelibrary.wiley.com/doi/10.1002/sim.7023/abstract">Balzer et al. 2016</a> and/or talk to us at UCB) . One final advantage of TMLE is that it will enable you to account for missing outcomes, which are common for some secondary specimen outcomes.</p>
<div id="paired-t-test-glm-and-tmle" class="section level3">
<h3 class="hasAnchor">
<a href="#paired-t-test-glm-and-tmle" class="anchor"></a>paired t-test, GLM, and TMLE</h3>
<p><strong>unadjusted analyses</strong></p>
<p>As seen below, the estimates and 95 percent confidence intervals are virtually the same across estimators in an unadjusted analysis, even in this finite sample example (Nutrition vs. Control LAZ).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># t-test</span>
ttest.C.N &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_ttest.html">washb_ttest</a></span>(<span class="dt">Y=</span>lazd<span class="op">$</span>laz,<span class="dt">tr=</span>lazd<span class="op">$</span>tr,<span class="dt">strat=</span>lazd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>))
<span class="kw">round</span>(ttest.C.N,<span class="dv">4</span>)</code></pre></div>
<pre><code>  diff  ci.lb  ci.ub t-stat      p 
0.2526 0.1470 0.3581 4.7545 0.0000 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># GLM, unadjusted</span>
LAZ.glm.C.N &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>lazd<span class="op">$</span>laz,<span class="dt">tr=</span>lazd<span class="op">$</span>tr,<span class="dt">pair=</span>lazd<span class="op">$</span>block, <span class="dt">id=</span>lazd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>), <span class="dt">family=</span><span class="st">"gaussian"</span>, <span class="dt">print=</span><span class="ot">FALSE</span>)
<span class="kw">round</span>(LAZ.glm.C.N<span class="op">$</span>TR,<span class="dv">4</span>)</code></pre></div>
<pre><code>             Coef.   2.5%  97.5% Std. Error z value Pr(&gt;|z|)
trNutrition 0.2427 0.1403 0.3451     0.0522  4.6467        0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># TMLE, unadjusted</span>
LAZ.tmle.C.N &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_tmle.html">washb_tmle</a></span>(<span class="dt">Y=</span>lazd<span class="op">$</span>laz,<span class="dt">tr=</span>lazd<span class="op">$</span>tr,<span class="dt">pair=</span>lazd<span class="op">$</span>block,<span class="dt">id=</span>lazd<span class="op">$</span>block, <span class="dt">W=</span><span class="ot">NULL</span>, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>), <span class="dt">family=</span><span class="st">"gaussian"</span>,<span class="dt">print=</span><span class="ot">FALSE</span>,<span class="dt">seed=</span><span class="dv">12345</span>)</code></pre></div>
<pre><code>
----------------------------------------- 
By specifying the pair argument,
you have indicated that this is a matched pair analysis.

Note: the analysis will only include pairs
that have a contrast in the treatment variable. 
-----------------------------------------</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">unlist</span>(LAZ.tmle.C.N<span class="op">$</span>estimates<span class="op">$</span>ATE),<span class="dv">4</span>)</code></pre></div>
<pre><code>    psi var.psi     CI1     CI2  pvalue 
 0.2549  0.0029  0.1495  0.3602  0.0000 </code></pre>
<p><strong>adjusted analyses</strong></p>
<p>The GLM and TMLE estimators are also similar in adjusted analyses. Below, we repeat the contrast above, also adjusting for pre-specified covariates by specifying <code>W=lazd[Wadj]</code>. In this particular example, the esitmates and confidence intervals are very similar between the two approaches. We have found over a large number of comparisons that the TMLE estimator is the same or more efficient than the GLM estimator.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># GLM, adjusted</span>
adj.LAZ.glm.C.N &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>lazd<span class="op">$</span>laz,<span class="dt">tr=</span>lazd<span class="op">$</span>tr,<span class="dt">pair=</span>lazd<span class="op">$</span>block, <span class="dt">id=</span>lazd<span class="op">$</span>block, <span class="dt">W=</span>lazd[Wadj], <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>), <span class="dt">family=</span><span class="st">"gaussian"</span>,  <span class="dt">print=</span><span class="ot">FALSE</span>)
<span class="kw">round</span>(adj.LAZ.glm.C.N<span class="op">$</span>TR,<span class="dv">4</span>)</code></pre></div>
<pre><code>            Coef. 2.5%  97.5% Std. Error z value Pr(&gt;|z|)
trNutrition 0.272 0.18 0.3641      0.047  5.7939        0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># TMLE, adjusted</span>
adj.LAZ.tmle.C.N &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_tmle.html">washb_tmle</a></span>(<span class="dt">Y=</span>lazd<span class="op">$</span>laz,<span class="dt">tr=</span>lazd<span class="op">$</span>tr,<span class="dt">pair=</span>lazd<span class="op">$</span>block,<span class="dt">id=</span>lazd<span class="op">$</span>block, <span class="dt">W=</span>lazd[Wadj], <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Nutrition"</span>), <span class="dt">family=</span><span class="st">"gaussian"</span>,<span class="dt">print=</span><span class="ot">FALSE</span>,<span class="dt">seed=</span><span class="dv">12345</span>)</code></pre></div>
<pre><code>
----------------------------------------- 
By specifying the pair argument,
you have indicated that this is a matched pair analysis.

Note: the analysis will only include pairs
that have a contrast in the treatment variable. 
-----------------------------------------</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">unlist</span>(adj.LAZ.tmle.C.N<span class="op">$</span>estimates<span class="op">$</span>ATE),<span class="dv">4</span>)</code></pre></div>
<pre><code>    psi var.psi     CI1     CI2  pvalue 
 0.2749  0.0023  0.1814  0.3683  0.0000 </code></pre>
</div>
<div id="mantel-haenszel-glm-and-tmle" class="section level3">
<h3 class="hasAnchor">
<a href="#mantel-haenszel-glm-and-tmle" class="anchor"></a>Mantel-Haenszel, GLM, and TMLE</h3>
<p><strong>unadjusted analysis</strong></p>
<p>As seen below, the estimates and 95 percent confidence intervals for the prevalence ratio of diarrhea (binary outcome) are virtually the same, even in this finite sample example (Sanitation vs. Control).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Mantel-Haenszel (estimated above)</span>
mh.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_mh.html">washb_mh</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">strat=</span>dd<span class="op">$</span>block,<span class="dt">measure=</span><span class="st">"RR"</span>)
<span class="kw">round</span>(mh.C.S,<span class="dv">4</span>)</code></pre></div>
<pre><code>     PR,    ci.lb    ci.ub    logPR se.logPR        Z        p 
  0.6085   0.4569   0.8102  -0.4968   0.1461  -3.4001   0.0007 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># GLM, unadjusted</span>
Diar.glm.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block, <span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'log'</span>),<span class="dt">print=</span><span class="ot">FALSE</span>)
<span class="kw">round</span>(Diar.glm.C.S<span class="op">$</span>TR,<span class="dv">4</span>)</code></pre></div>
<pre><code>                 PR  2.5%  97.5% Estimate Std. Error z value Pr(&gt;|z|)
trSanitation 0.6109 0.451 0.8275  -0.4928     0.1548  -3.183   0.0015</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># TMLE, unadjusted</span>
Diar.tmle.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_tmle.html">washb_tmle</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block,<span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">W=</span><span class="ot">NULL</span>, <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="st">"binomial"</span>,<span class="dt">print=</span><span class="ot">FALSE</span>,<span class="dt">seed=</span><span class="dv">12345</span>)</code></pre></div>
<pre><code>
----------------------------------------- 
By specifying the pair argument,
you have indicated that this is a matched pair analysis.

Note: the analysis will only include pairs
that have a contrast in the treatment variable. 
-----------------------------------------</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">unlist</span>(Diar.tmle.C.S<span class="op">$</span>estimates<span class="op">$</span>RR),<span class="dv">4</span>)</code></pre></div>
<pre><code>        psi         CI1         CI2      pvalue     log.psi var.log.psi 
     0.6096      0.4529      0.8205      0.0011     -0.4950      0.0230 </code></pre>
<p><strong>adjusted analyses</strong></p>
<p>The GLM and TMLE estimators are also similar in adjusted analyses. Below, we repeat the contrast above, also adjusting for pre-specified covariates by specifying <code>W=dd[Wadj]</code>. In this particular example, the estimates and confidence intervals are very similar between the two approaches. We have found over a large number of comparisons that the TMLE estimator is the same or more efficient than the GLM estimator.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># GLM, adjusted</span>
adj.Diar.glm.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_glm.html">washb_glm</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block, <span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">W=</span>dd[Wadj],<span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'log'</span>),<span class="dt">print=</span><span class="ot">FALSE</span>)
<span class="kw">round</span>(adj.Diar.glm.C.S<span class="op">$</span>TR,<span class="dv">4</span>)</code></pre></div>
<pre><code>                 PR   2.5%  97.5% Estimate Std. Error z value Pr(&gt;|z|)
trSanitation 0.5847 0.4318 0.7919  -0.5366     0.1547 -3.4677   0.0005</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># TMLE, adjusted</span>
adj.Diar.tmle.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_tmle.html">washb_tmle</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">tr=</span>dd<span class="op">$</span>tr,<span class="dt">pair=</span>dd<span class="op">$</span>block,<span class="dt">id=</span>dd<span class="op">$</span>block, <span class="dt">W=</span>dd[Wadj], <span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">family=</span><span class="st">"binomial"</span>,<span class="dt">print=</span><span class="ot">FALSE</span>,<span class="dt">seed=</span><span class="dv">12345</span>)</code></pre></div>
<pre><code>
----------------------------------------- 
By specifying the pair argument,
you have indicated that this is a matched pair analysis.

Note: the analysis will only include pairs
that have a contrast in the treatment variable. 
-----------------------------------------</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">unlist</span>(adj.Diar.tmle.C.S<span class="op">$</span>estimates<span class="op">$</span>RR),<span class="dv">4</span>)</code></pre></div>
<pre><code>        psi         CI1         CI2      pvalue     log.psi var.log.psi 
     0.6014      0.4473      0.8087      0.0008     -0.5084      0.0228 </code></pre>
</div>
</div>
<div id="washb_permute" class="section level1">
<h1 class="hasAnchor">
<a href="#washb_permute" class="anchor"></a>washb_permute</h1>
<p>Non-parametric test of complete independence (i.e., the strong null hypothesis) using the Wilcoxon Signed Rank permutation test.</p>
<div id="function-overview-5" class="section level3">
<h3 class="hasAnchor">
<a href="#function-overview-5" class="anchor"></a>function overview</h3>
<p>WASH Benefits Wilcoxon Signed Rank permutation test function for two treatment arms conditional on randomization block. It conducts a permutation test of the independence of <code>Y</code> and <code>tr</code>, conditional on matched pair (randomization block) using the Wilcoxon rank-sum test statistic.</p>
<p>The <code>washb_glm</code> and related functions (above) enable us to test hypotheses about whether the average outcome differs between trial arms – that is, whether the difference in means is equal to zero. The mean is just one function of the outcome distribution. A sharper test is the “sharp null hypothesis” first proposed by Ronald Fisher, in which we test whether there is any difference at all in the outcome distributions between intervention arms. Under the null hypothesis of no treatment effect, the outcome distributions should be indistinguishable from random sampling variation. A way to test the sharp null hypothesis is with a permutation test (also called a Fisher randomization test). The intuition behind the test is that there is a single source of random variation in the trial: namely the random allocation of treatment. If we re-randomize treatment in every possible combination (or a very large number of combinations), and compare arms using a test statistic for each combination, then this provides us with the test statistic’s distribution under the null hypothesis of no effect (since we re-shuffle treatment in each iteration, it is completely uninformative). We can then compare the observed test statistic with real group assignments to the null distribution to see how likely it would be to have occurred by chance. For more details on randomization tests, see the references below.</p>
<p>In the WASH Benefits primary analysis, we pre-specified that we would test this sharp null using a Wilcoxon signed rank test, which is a non-parametric test statistic that has been shown to have good power against alternatives for outcomes that could potentially have skewed distributions <a href="http://dl.acm.org/citation.cfm?id=2764565">Imbens GW, Rubin DB. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press; 2015.</a>.</p>
<p>Note, however, that in every test we have performed, p-values obtained under this strong null hypothesis have been entirely consistent with p-values obtained from paired t-tests, Mantel-Haenszel chi-squared tests, and even adjusted estimates. Therefore, going the extra mile to estimate these tests may be unnecessary for many analyses in the WASH Benefits trials. Nevertheless, we have included the function in the package because it might be useful.</p>
<p><strong>Arguments:</strong><br><code>Y</code>= Outcome variable (continuous, such as LAZ, or binary, such as diarrhea).<br><code>tr</code>= Binary treatment group variable (ideally a factor), comparison group first.<br><code>pair</code>= Pair-matched randomization ID variable (in WASH Benefits: block).<br><code>contrast</code>= Vector of length 2 that includes the groups to contrast, e.g., c(“Control”,“Water”).<br><code>nreps</code>= Number of permutations to run.<br><code>seed</code>= Number for psuedo-random number generation in R.</p>
<p><strong>Usage:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/washb_permute.html">washb_permute</a></span>(Y,tr,pair,contrast,<span class="dt">nreps=</span><span class="dv">100000</span>,<span class="dt">seed=</span><span class="ot">NULL</span>)</code></pre></div>
<p><strong>References:</strong><br>
1. Gail, M. H., Mark, S. D., Carroll, R. J., Green, S. B. &amp; Pee, D. On Design Considerations and Randomization-Based Inference for Community Intervention Trials. Statist. Med. 15, 1069–1092 (1996).<a href="http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0258(19960615)15:11%3c1069::AID-SIM220%3e3.0.CO%3b2-Q/full">Link</a></p>
<ol start="2" style="list-style-type: decimal">
<li><p>Braun, T. M. &amp; Feng, Z. Optimal Permutation Tests for the Analysis of Group Randomized Trials. Journal of the American Statistical Association 96, 1424–1432 (2001). <a href="http://www.tandfonline.com/doi/abs/10.1198/016214501753382336">Link</a></p></li>
<li><p>Rosenbaum, P. R. Covariance Adjustment in Randomized Experiments and Observational Studies. Statist. Sci. 17, 286–327 (2002). <a href="http://projecteuclid.org/euclid.ss/1042727942">Link</a></p></li>
</ol>
</div>
<div id="unadjusted-permutation-test" class="section level3">
<h3 class="hasAnchor">
<a href="#unadjusted-permutation-test" class="anchor"></a>unadjusted permutation test</h3>
<p>Apply the <code>washb_permute</code> function to the Sanitation-Control arm comparison for diarrhea:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">permute.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_permute.html">washb_permute</a></span>(<span class="dt">Y =</span> dd<span class="op">$</span>diar7d, <span class="dt">tr =</span> dd<span class="op">$</span>tr, <span class="dt">pair =</span> dd<span class="op">$</span>block, <span class="dt">contrast =</span> <span class="kw">c</span>(<span class="st">"Control"</span>, <span class="st">"Sanitation"</span>), <span class="dt">nreps =</span> <span class="dv">100000</span>, <span class="dt">seed =</span> <span class="dv">242524</span>)</code></pre></div>
<pre><code>
    Approximative Wilcoxon-Pratt Signed-Rank Test

data:  y by x (pos, neg) 
     stratified by block
Z = 3.551, p-value = 0.00032
alternative hypothesis: true mu is not equal to 0</code></pre>
</div>
<div id="adjusted-permutation-test" class="section level3">
<h3 class="hasAnchor">
<a href="#adjusted-permutation-test" class="anchor"></a>adjusted permutation test</h3>
<p>The permutation test can also test for independence of <code>Y</code> and <code>tr</code>, conditional on <code>W</code>, by applying the <code>washb_permute</code> function to the residuals of an adjusted model (adjusted for <code>W</code>, but not <code>tr</code>). The permutation test can have even greater power against alternatives if it is conducted on residuals from an algorithmic fit that removes variability of the outcome due to characteristics other than treatment. The intuition is that by removing outcome variability that is not associated with the treatment of interest, we can more narrowly focus our inference on differences due to treatment. In the example below, we show how to use a simple linear regression to predict LAZ, and then conduct the permutation test on the residuals from the regression. Alternatively, a more flexible, machine-learning algorithm approach, such as super learner, can be used in the initial prediction step.</p>
<p>Here is an example of an adjusted permutation test, using linear regression to adjust for covariates:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use the washb_prescreen function to select adjustment covariates associated with the outcome</span>
adj.W&lt;-<span class="kw"><a href="../reference/washb_prescreen.html">washb_prescreen</a></span>(<span class="dt">Y=</span>lazd<span class="op">$</span>laz,lazd[Wadj],<span class="dt">family=</span><span class="st">"gaussian"</span>, <span class="dt">pval=</span><span class="fl">0.2</span>)

<span class="co">#Subset the LAZ dataset to control and nutrition arms:</span>
      laz.subset=lazd[<span class="kw">which</span>(lazd<span class="op">$</span>tr<span class="op">==</span><span class="st">"Control"</span><span class="op">|</span>lazd<span class="op">$</span>tr<span class="op">==</span><span class="st">"Nutrition"</span>),]

<span class="co">#Subset the LAZ dataset to the selected adjustment covariates and LAZ, as well as tr and block, which will be needed in the permutation test</span>
perm.adj.data &lt;-<span class="st"> </span><span class="kw">subset</span>(laz.subset,<span class="dt">select=</span><span class="kw">c</span>(adj.W, <span class="st">"laz"</span>, <span class="st">"tr"</span>, <span class="st">"block"</span>))

<span class="co">#Subset to complete cases</span>
perm.adj.data&lt;-perm.adj.data[<span class="kw">complete.cases</span>(perm.adj.data),]

Wselect &lt;-<span class="st"> </span><span class="kw">subset</span>(perm.adj.data,<span class="dt">select=</span><span class="kw">c</span>(adj.W, <span class="st">"laz"</span>))
<span class="co">#fit the glm model</span>
fit &lt;-<span class="st"> </span><span class="kw">glm</span>(laz<span class="op">~</span>., <span class="dt">family=</span><span class="st">"gaussian"</span>, <span class="dt">data=</span>Wselect)

<span class="co">#Use the predict to return predicted LAZ from the adjusted glm model, and subtract it from the observed LAZ outcome</span>
residuals&lt;-Wselect<span class="op">$</span>laz<span class="op">-</span><span class="kw">predict</span>(fit)

<span class="co">#run the permutation test function</span>
permute.adj.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_permute.html">washb_permute</a></span>(<span class="dt">Y=</span>residuals,<span class="dt">tr=</span>perm.adj.data<span class="op">$</span>tr,<span class="dt">pair=</span>perm.adj.data<span class="op">$</span>block,<span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>), <span class="dt">nreps=</span><span class="dv">100000</span>,<span class="dt">seed=</span><span class="dv">12345</span>)</code></pre></div>
<p>And here is an example of using an adaptive algorithm, super learner, to estimate the residuals in advance of the permutation test:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># pre-screen the covariates for those associated with the outcome (LR test P&lt;0.2)</span>
<span class="co"># uses internal functions washb_prescreen and design_matrix</span>
<span class="co"># subset to complete observations (no missing values)</span>
adjpdata &lt;-<span class="st"> </span><span class="kw">subset</span>(lazd,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">"laz"</span>,<span class="st">"block"</span>,<span class="st">"tr"</span>,Wadj))
adjpdata &lt;-<span class="st"> </span>adjpdata[<span class="kw">complete.cases</span>(adjpdata),]
Wscreen &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_prescreen.html">washb_prescreen</a></span>(<span class="dt">Y=</span>adjpdata<span class="op">$</span>laz,<span class="dt">Ws=</span>adjpdata[Wadj],<span class="dt">family=</span><span class="st">"gaussian"</span>)</code></pre></div>
<pre><code>
Likelihood Ratio Test P-values:
               P-value
month          0.00000
agedays        0.69656
sex            0.41464
momage         0.26153
momedu         0.00000
momheight      0.00000
hfiacat        0.00000
Nlt18          0.00005
Ncomp          0.00135
watmin         0.74293
elec           0.00000
floor          0.00000
walls          0.63752
roof           0.02256
asset_wardrobe 0.00000
asset_table    0.00000
asset_chair    0.00000
asset_khat     0.00000
asset_chouki   0.00000
asset_tv       0.00000
asset_refrig   0.00000
asset_bike     0.00000
asset_moto     0.00000
asset_sewmach  0.00000
asset_mobile   0.00000


Covariates selected (P&lt;0.2):
                     P-value
month           3.071077e-11
momedu          3.376024e-37
momheight      5.954595e-136
hfiacat         7.311145e-17
Nlt18           4.959634e-05
Ncomp           1.347806e-03
elec            1.117490e-19
floor           1.936064e-24
roof            2.256134e-02
asset_wardrobe  8.744450e-29
asset_table     3.372179e-19
asset_chair     6.383480e-26
asset_khat      8.252063e-33
asset_chouki    8.884088e-07
asset_tv        1.896792e-33
asset_refrig    1.229590e-35
asset_bike      8.952416e-07
asset_moto      2.026057e-13
asset_sewmach   2.865749e-14
asset_mobile    5.007999e-21</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># convert adjustment covariates into a full design matrix</span>
Wselect &lt;-<span class="st"> </span><span class="kw">subset</span>(adjpdata,<span class="dt">select=</span>Wscreen)
Wselect &lt;-<span class="st"> </span><span class="kw"><a href="../reference/design_matrix.html">design_matrix</a></span>(Wselect)

<span class="co"># algorithmic fit of the outcome as a function of selected covariates</span>
<span class="kw">set.seed</span>(<span class="dv">12345</span>)
SLfit1 &lt;-<span class="st"> </span><span class="kw">SuperLearner</span>(<span class="dt">Y=</span>adjpdata<span class="op">$</span>laz,<span class="dt">X=</span>Wselect,<span class="dt">id=</span>adjpdata<span class="op">$</span>block,
                       <span class="dt">family=</span><span class="st">"gaussian"</span>,
                    <span class="dt">SL.library=</span><span class="kw">c</span>(<span class="st">"SL.mean"</span>,<span class="st">"SL.glm"</span>,<span class="st">"SL.bayesglm"</span>,<span class="st">"SL.gam"</span>,<span class="st">"SL.glmnet"</span>)
                       )
SLfit1</code></pre></div>
<pre><code>
Call:  SuperLearner(Y = adjpdata$laz, X = Wselect, family = "gaussian", SL.library = c("SL.mean", "SL.glm", "SL.bayesglm", "SL.gam", "SL.glmnet"), id = adjpdata$block) 

                     Risk      Coef
SL.mean_All     1.0541483 0.0000000
SL.glm_All      0.8665921 0.0000000
SL.bayesglm_All 0.8665833 0.0000000
SL.gam_All      0.8666606 0.3591644
SL.glmnet_All   0.8656952 0.6408356</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">adjpdata<span class="op">$</span>pY &lt;-<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">predict</span>(SLfit1)<span class="op">$</span>pred)
adjpdata<span class="op">$</span>r &lt;-<span class="st"> </span>adjpdata<span class="op">$</span>laz<span class="op">-</span>adjpdata<span class="op">$</span>pY

<span class="co"># Test of the strong-null hypothesis for differences between sanitation and control arms in LAZ distributions</span>
permute.sl.C.S &lt;-<span class="st"> </span><span class="kw"><a href="../reference/washb_permute.html">washb_permute</a></span>(<span class="dt">Y=</span>adjpdata<span class="op">$</span>r,<span class="dt">tr=</span>adjpdata<span class="op">$</span>tr,<span class="dt">pair=</span>adjpdata<span class="op">$</span>block,<span class="dt">contrast=</span><span class="kw">c</span>(<span class="st">"Control"</span>,<span class="st">"Sanitation"</span>),<span class="dt">nreps=</span><span class="dv">100000</span>,<span class="dt">seed=</span><span class="dv">12345</span>)</code></pre></div>
<pre><code>
    Approximative Wilcoxon-Pratt Signed-Rank Test

data:  y by x (pos, neg) 
     stratified by block
Z = -0.46071, p-value = 0.648
alternative hypothesis: true mu is not equal to 0</code></pre>
</div>
</div>
<div id="washb_prescreen-internal" class="section level1">
<h1 class="hasAnchor">
<a href="#washb_prescreen-internal" class="anchor"></a>washb_prescreen (internal)</h1>
<p><strong>Note:</strong> The <code>washb_prescreen</code> function was written as internal function (called by <code>washb_glm</code> and <code>washb_tmle</code>), but we have provided some additional details for how they work in case investigators wish to use them separately.</p>
<p>The <code>washb_prescreen</code> function selects covariates with univariate associations with the outcome of P&lt;0.2 (default) based on a likelihood ratio test. It is called as a part of the <code>washb_glm</code> function to select adjustment covariates, but can also be run as an independent function. The <code>pval=</code> argument can be used to alter the p-value threshold for inclusion.</p>
<p><strong>Arguments:</strong><br><code>Y</code> Outcome variable (continuous, such as LAZ, or binary, such as diarrhea).<br><code>Ws</code> data frame that includes candidate adjustment covariates to screen.<br><code>family</code> GLM model family (<code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>binomial(link='log')</code>, or <code>"neg.binom"</code> for negative binomial).<br><code>pval</code> The p-value threshold: any variables with a p-value from the likelihood ratio test below this threshold will be returned. Defaults to 0.2.<br><code>print</code> Logical for whether to print function output, defaults to TRUE.</p>
<p><strong>Usage:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/washb_prescreen.html">washb_prescreen</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,<span class="dt">Ws=</span>W,<span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'log'</span>), <span class="dt">pval=</span><span class="fl">0.2</span>, <span class="dt">print=</span><span class="ot">TRUE</span>)</code></pre></div>
<div id="run-the-washb_prescreen-function" class="section level3">
<h3 class="hasAnchor">
<a href="#run-the-washb_prescreen-function" class="anchor"></a>run the washb_prescreen function</h3>
<p>The <code>washb_prescreen</code> function performs a likelihood ratio test on a set of potential covariates and returns all covariates with an associated p-value&lt;0.2 (unless a custom pvalue is specified). It can be called as a function on its own, and is also called internally within the washb_glm function. Unless otherwise specified by the use, the washb_glm function with therefore only include covariates with a LR-test p-value &lt;0.2 in the model. See the Function: washb_glm section for more details.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prescreened_varnames&lt;-<span class="kw"><a href="../reference/washb_prescreen.html">washb_prescreen</a></span>(<span class="dt">Y=</span>dd<span class="op">$</span>diar7d,dd[Wadj],<span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'log'</span>), <span class="dt">pval=</span><span class="fl">0.2</span>)</code></pre></div>
<pre><code>
Likelihood Ratio Test P-values:
               P-value
month          0.00000
agedays        0.00001
sex            0.15910
momage         0.85843
momedu         0.00113
momheight      0.83679
hfiacat        0.00044
Nlt18          0.14607
Ncomp          0.85849
watmin         0.01745
elec           0.00166
floor          0.00882
walls          0.17286
roof           0.44633
asset_wardrobe 0.00334
asset_table    0.27762
asset_chair    0.26366
asset_khat     0.05397
asset_chouki   0.88290
asset_tv       0.10924
asset_refrig   0.01527
asset_bike     0.00498
asset_moto     0.23256
asset_sewmach  0.00352
asset_mobile   0.71326


Covariates selected (P&lt;0.2):
                      P-value
month          0.000001277665
agedays        0.000008578316
sex            0.159101014584
momedu         0.001131482118
hfiacat        0.000436393481
Nlt18          0.146074279888
watmin         0.017447529756
elec           0.001659255089
floor          0.008816329210
walls          0.172858463464
asset_wardrobe 0.003338351150
asset_khat     0.053968452008
asset_tv       0.109235025959
asset_refrig   0.015267527279
asset_bike     0.004977085684
asset_sewmach  0.003515782703</code></pre>
</div>
<div id="description-of-output" class="section level3">
<h3 class="hasAnchor">
<a href="#description-of-output" class="anchor"></a>description of output</h3>
<p>The function runs a likelihood ratio test between a generalized linear model fit to each screened variable and a null model. The first section of the output includes all screened variables and the p-values from the likelihood ratio test. The second section outputs only those variables with a p-value less than the thresholds set with the <code>pval</code> argument (&lt;0.2 by default).</p>
<p>Use the following code to return the saved a list of variable names for the selected variables. Then, subset the covariate dataframe to only those variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prescreened_varnames</code></pre></div>
<pre><code> [1] "month"          "agedays"        "sex"            "momedu"         "hfiacat"        "Nlt18"          "watmin"         "elec"           "floor"          "walls"          "asset_wardrobe" "asset_khat"     "asset_tv"       "asset_refrig"   "asset_bike"     "asset_sewmach" </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prescreened_vars &lt;-<span class="st"> </span><span class="kw">subset</span>(dd[Wadj],<span class="dt">select=</span>prescreened_varnames)
<span class="co"># Examine the first five observations of the second selected variable, child age in days:</span>
prescreened_vars[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,<span class="dv">2</span>]</code></pre></div>
<pre><code>[1]  346  810 1289 1753 1780</code></pre>
</div>
</div>
<div id="washb_lincom-internal" class="section level1">
<h1 class="hasAnchor">
<a href="#washb_lincom-internal" class="anchor"></a>washb_lincom (internal)</h1>
<p><strong>Note:</strong> <code>washb_lincom</code> function was written as an internal function (called by washb_glm, above), but we have provided some additional details for how it works in case investigators wish to use it separately.</p>
<p>The subgroup analysis option in <code>washb_glm</code> internally calls the <code>washb_lincom</code> function to calculate estimates, SEs, CIs, and P-values from a linear combination of regression coefficients. The <code>washb_lincom</code> function can be called alone to calculate a custom linear combination of coefficients.</p>
<p><strong>Arguments:</strong><br><code>lc</code>= Index vector of coefficients from glm modellinear combination of coefficients <code>varlist</code>= Character vector of variables to include. Alternative to lc. If lc is specified, this argument is ignored. <code>fit</code>= Model object returned from coeftest (class=coeftest) command within the washb_glm function. Accessed with $fit from washb_glm output. <code>vcv</code>= variance-covariance matrix of coefficients. Accessed with $vcv from washb_glm output. <code>measure</code>= measure of effect. RR = risk ratio, RD = risk difference <code>flag</code>= Internal argument used to flag and suppress printing if the washb_lincom function is called within another function.</p>
<p><strong>Usage:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/washb_lincom.html">washb_lincom</a></span>(<span class="dt">lc=</span><span class="ot">NULL</span>,<span class="dt">varlist=</span><span class="ot">NULL</span>,fit,vcv, <span class="dt">measure=</span><span class="st">"RR"</span>, <span class="dt">flag=</span><span class="ot">NULL</span>)</code></pre></div>
<div id="index-child-v--sibling-subgroup-analysis" class="section level3">
<h3 class="hasAnchor">
<a href="#index-child-v--sibling-subgroup-analysis" class="anchor"></a>Index child v. sibling subgroup analysis</h3>
<p>Below is an example of using the <code>lincom()</code> function to externally replicate the index child/sibling subgroup analysis of the diarrheal disease outcome. First, recall the GLM model contrasting diarrheal disease prevalence ratio between index child and sibling fitted to diarrheal disease:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm.C.N.byChildType<span class="op">$</span>lincom</code></pre></div>
<pre><code>  Tr vs. C by Subgroup     est se.est  est.lb  est.ub       Z      P
1              Sibling -0.0144 0.0103 -0.0346  0.0058 -1.3978 0.1622
2         Target child -0.0226 0.0080 -0.0383 -0.0068 -2.8116 0.0049</code></pre>
<p>Next, use the lincom function to verify the subgroup analysis calculated within the <code><a href="../reference/washb_glm.html">washb_glm()</a></code> function. <code><a href="../reference/washb_lincom.html">washb_lincom()</a></code> takes as arguments the fit and variance-covariance matrix returned by the glm function, and an index vector <code>lc</code>.<br><code>lc</code>= vector indexing coefficients to be linearly combined. If a single coefficient is chosen, it will return the same coefficient and confidence interval as the GLM coefficient. Example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="co">#Create lc vector of 0's equal in length to the number of coefficients from the glm model.</span>
lc=<span class="kw">rep</span>(<span class="dv">0</span>,<span class="kw">nrow</span>(glm.C.N.byChildType<span class="op">$</span>fit))
<span class="co">#Examine model coefficients (minus the pair-matched block estimates) to determine the position of coefficients to combine.</span>
glm.C.N.byChildType<span class="op">$</span>fit[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,]</code></pre></div>
<pre><code>                    Coef.        2.5%      97.5%  Std. Error    z value    Pr(&gt;|z|)
(Intercept)    0.00644170 -0.00641030 0.01929369 0.006557140  0.9823943 0.325905625
trNutrition   -0.01440157 -0.03459600 0.00579286 0.010303280 -1.3977654 0.162183529
VTarget child  0.02491546  0.00632508 0.04350584 0.009484888  2.6268585 0.008617717</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="co">#Replace the second position in the vector with 1 (the position of the treatment coefficient in the model)</span>
lc[<span class="dv">2</span>]&lt;-<span class="dv">1</span>
  <span class="co">#Run the lincom function and compare output to the treatment effect from the GLM model.</span>
<span class="kw"><a href="../reference/washb_lincom.html">washb_lincom</a></span>(<span class="dt">lc=</span>lc,<span class="dt">fit=</span>glm.C.N.byChildType<span class="op">$</span>fit,<span class="dt">vcv=</span>glm.C.N.byChildType<span class="op">$</span>vcv, <span class="dt">measure=</span><span class="st">"RR"</span>)</code></pre></div>
<pre><code>
Linear combination of coefficients:
[1] "trNutrition"</code></pre>
<pre><code>         RR  se.RR  RR.lb RR.ub Z      P
[1,] 1.0104 0.0103 0.9902 1.031 1 0.3173</code></pre>
<p>Because sibling is the reference level of the <code>VTarget child</code> term, running the <code>lincom()</code> function with only the treatment contrast term marked in the <code>lc</code> index vector equals both the prevalence ratio of the <code>trSanitation</code> term and the prevalence ratio of the sibling subgroup returned in the <code>glm.C.S.byChildType$lincom</code> object. To estimate the PR from the target child subgroup, the interaction term <code>trSanitation:VTarget child</code> needs to be marked in the <code>lc</code> index.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Add a 1 at the 4th position in the lc vector to include the 4th coefficient, the interaction term, in the linear combination.</span>
lc[<span class="dv">4</span>]&lt;-<span class="dv">1</span>
<span class="kw"><a href="../reference/washb_lincom.html">washb_lincom</a></span>(<span class="dt">lc=</span>lc,<span class="dt">fit=</span>glm.C.N.byChildType<span class="op">$</span>fit,<span class="dt">vcv=</span>glm.C.N.byChildType<span class="op">$</span>vcv, <span class="dt">measure=</span><span class="st">"RR"</span>)</code></pre></div>
<pre><code>
Linear combination of coefficients:
[1] "trNutrition + pair2"</code></pre>
<pre><code>         RR  se.RR  RR.lb  RR.ub      Z      P
[1,] 1.0116 0.0091 0.9936 1.0299 1.2624 0.2068</code></pre>
<p>This estimate equals the target child PR estimated in the <code>washb_glm</code> estimate with the <code>V</code> argument specified. Note that the coefficient for the <code>VTarget child</code> term is not included in this linear combination calculation. Including that term would calculate the prevalence ratio between sanitation arm target children and control arm siblings, whereas in a subgroup analysis the prevalence ratio between treatments within, rather than across, the groups is desired.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#vignette-overview">Vignette overview</a></li>
      <li><a href="#getting-started">Getting started</a></li>
      <li><a href="#washb_mean">washb_mean</a></li>
      <li><a href="#washb_ttest">washb_ttest</a></li>
      <li><a href="#washb_mh">washb_mh</a></li>
      <li><a href="#washb_glm">washb_glm</a></li>
      <li><a href="#washb_tmle">washb_tmle</a></li>
      <li><a href="#comparison-of-itt-estimators">Comparison of ITT estimators</a></li>
      <li><a href="#washb_permute">washb_permute</a></li>
      <li><a href="#washb_prescreen-internal">washb_prescreen (internal)</a></li>
      <li><a href="#washb_lincom-internal">washb_lincom (internal)</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Andrew Mertens, Ben Arnold, Anna Nguyen <anna-nguyen></anna-nguyen></p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
